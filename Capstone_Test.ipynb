{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# RESTAURANT MENU RECOMMENDER"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### We poped into one of the restaurant's today & were confused after seeing the long menu card and innovative names. \n#### Sometimes a common man might not know what the dish actually means so he just needs to know what do I order from this long menu.\n#### In such cases earlier reviews might be helpful but there is lot of noise in it and you need to find out which dishes people are recommending.\n#### This program will read all the restaurant, review information from Zomato and do a basic sentiment analysis telling what people recommend for a restaurant"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Lets begin by installing some libraries we would require"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "!pip install dropbox",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Collecting dropbox\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/37/1874bedfdbac91c8abfb1ddb133599306d65fca44dcd592fa5e84afbf181/dropbox-9.4.0-py3-none-any.whl (543kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 552kB 7.3MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: six>=1.3.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from dropbox) (1.12.0)\nRequirement already satisfied: requests>=2.16.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from dropbox) (2.21.0)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests>=2.16.2->dropbox) (3.0.4)\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests>=2.16.2->dropbox) (1.24.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests>=2.16.2->dropbox) (2019.11.28)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests>=2.16.2->dropbox) (2.8)\nInstalling collected packages: dropbox\nSuccessfully installed dropbox-9.4.0\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!pip install contractions",
            "execution_count": 2,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Collecting contractions\n  Downloading https://files.pythonhosted.org/packages/85/41/c3dfd5feb91a8d587ed1a59f553f07c05f95ad4e5d00ab78702fbf8fe48a/contractions-0.0.24-py2.py3-none-any.whl\nCollecting textsearch (from contractions)\n  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\nCollecting pyahocorasick (from textsearch->contractions)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 317kB 10.8MB/s eta 0:00:01\n\u001b[?25hCollecting Unidecode (from textsearch->contractions)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 245kB 29.4MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n  Building wheel for pyahocorasick (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\nSuccessfully built pyahocorasick\nInstalling collected packages: pyahocorasick, Unidecode, textsearch, contractions\nSuccessfully installed Unidecode-1.1.1 contractions-0.0.24 pyahocorasick-1.4.0 textsearch-0.0.17\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!pip install TextBlob",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Collecting TextBlob\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/f0/1d9bfcc8ee6b83472ec571406bd0dd51c0e6330ff1a51b2d29861d389e85/textblob-0.15.3-py2.py3-none-any.whl (636kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 645kB 6.0MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: nltk>=3.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from TextBlob) (3.4)\nRequirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from nltk>=3.1->TextBlob) (1.12.0)\nRequirement already satisfied: singledispatch in /opt/conda/envs/Python36/lib/python3.6/site-packages (from nltk>=3.1->TextBlob) (3.4.0.3)\nInstalling collected packages: TextBlob\nSuccessfully installed TextBlob-0.15.3\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!pip install num2words",
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Collecting num2words\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/a2/ea800689730732e27711c41beed4b2a129b34974435bdc450377ec407738/num2words-0.5.10-py3-none-any.whl (101kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 102kB 13.0MB/s ta 0:00:01\n\u001b[?25hCollecting docopt>=0.6.2 (from num2words)\n  Downloading https://files.pythonhosted.org/packages/a2/55/8f8cab2afd404cf578136ef2cc5dfb50baa1761b68c9da1fb1e4eed343c9/docopt-0.6.2.tar.gz\nBuilding wheels for collected packages: docopt\n  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/9b/04/dd/7daf4150b6d9b12949298737de9431a324d4b797ffd63f526e\nSuccessfully built docopt\nInstalling collected packages: docopt, num2words\nSuccessfully installed docopt-0.6.2 num2words-0.5.10\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## I will be doing REST API calls to ZOMATO API so importing libraries needed for it"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import requests as rq\nimport json\nimport pandas as pd\nimport dropbox\nfrom pandas.io.json import json_normalize",
            "execution_count": 5,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "headers = {}",
            "execution_count": 6,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Lets begin by defining a module for each function"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def initialize(api_key):\n    '''\n    func to intialize the headers for the request URL like api key etc.\n    '''\n    headers = {\n    'Accept': 'application/json',\n    'user-key': api_key,\n    }\n    return headers",
            "execution_count": 7,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def make_query(func,args):\n\n    '''\n    func - the call made to the API. eg. reviews/locations/restaurants/collections etc\n    args - arguments to be passed alongwith a particular func call\n    '''\n\n    #construct the query\n    req_url = \"https://developers.zomato.com/api/v2.1/\"\n    req_url=req_url+func\n    key_index=0\n    for key, value in args.items() :\n        if key_index == 0:\n            req_url=req_url+\"?\"+key+\"=\"+value\n        else:\n            req_url=req_url+\"&\"+key+\"=\"+value\n        key_index+=1\n    \n    return execute_query(req_url)",
            "execution_count": 8,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def execute_query(query):\n    '''\n    query - object of class zomatoApiRequest\n    headers - dict of meta data for API call\n    '''\n    response=rq.get(query,headers=headers)\n    return(response.json())",
            "execution_count": 9,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def getLocation(location_name):\n    '''\t\n    get details of most relevant locations searched by name\n    '''\n    func = \"locations\"\n    args = { 'query': location_name }\n    output = make_query(func,args)\n    if (checkKey(output,'location_suggestions') == 1):\n        print(\"location found\")\n    else:\n        print(\"location key not found in this iteration\")\n    return output['location_suggestions'][0]",
            "execution_count": 10,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def getCollections(city_id):\n    '''\t\n    get details of collection\n    '''\n    func = \"collections\"\n    args =dict()\n    args[\"city_id\"] = city_id\n    output = make_query(func,args)\n    if (checkKey(output,'collections') == 1):\n        print(\"collections found \")\n    else:\n        print(\"collections key not found in this iteration\")\n    return(output['collections'])",
            "execution_count": 11,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def getReviews(res_id):\n    '''\t\n    get details of reviews\n    '''\n    func = \"reviews\"\n    args =dict()\n    args[\"res_id\"] = res_id\n    output = make_query(func,args)\n    if (checkKey(output,'reviews_shown') == 1):\n        print(\"reviews found\")\n    else:\n        print(\"reviews key not found in this iteration\")\n    return(output['user_reviews'])",
            "execution_count": 12,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def search(city_id,collection_id,start=0,count=1):\n    '''\n    get restaurants for the given location(entity_id); other args - cuisines/collections/category and sorting & counts for fetching how many at a time\n    '''\n    func = \"search\"\n    args = { 'entity_id':city_id, 'entity_type':'city', 'start':str(start), 'count':str(count),'collection_id':collection_id,'sort':'rating','order':'desc'}\n    output = make_query(func,args)\n    return(output)",
            "execution_count": 13,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def checkKey(dict, key):\n    '''\t\n    func to check if a dictionary key exists before taking any actions on it\n    '''\n    if key in dict.keys(): \n        return 1\n    else: \n        return 0",
            "execution_count": 14,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def extract_resto_and_reviews(collection_id,output,total_results):\n    '''\t\n    func to extract all restaurants within a collection. This will iterate multiple times as one API call gives on 20 restaurants\n    We will populate all the data from the JSON objects into individual lists & finally append to a dictonary which can be easily converted to a pandas frame\n    '''\n    restro_temp_list = []\n    resto_index = 0\n    restro_temp_list.append(output['restaurants'])\n    #print(\"Length of resto temp list \",len(restro_temp_list))\n    for i in range(0,len(restro_temp_list)): #always len(restro_temp_list) = 1 \n        try:\n            for rest_dict_val in restro_temp_list[i]: #loop for restaturants within a collection                   \n\n                if resto_index <=total_results: #till we get data for all restaurants in this collection  \n                    if (checkKey(rest_dict_val,'restaurant') == 1):\n                        #print(\"processing res_id \", rest_dict_val['restaurant']['id'])\n                        collection_id_list.append(collection_id)\n                        rest_id_list.append(rest_dict_val['restaurant']['id'])\n                        rest_name_list.append(rest_dict_val['restaurant']['name'])\n                        rest_locality_list.append(rest_dict_val['restaurant']['location']['locality'])\n                        rest_user_rating_list.append(rest_dict_val['restaurant']['user_rating']['aggregate_rating'])\n\n                        rev_output_list = getReviews(str(rest_dict_val['restaurant']['id']))\n\n                        for rev_text_dict_val in rev_output_list: #loop for reviews within a restaurant\n                            if (checkKey(rev_text_dict_val,'review') == 1):\n                                if rev_text_dict_val['review']['review_text'] != '':\n                                    review_rest_id_list.append(rest_dict_val['restaurant']['id'])\n                                    review_id_list.append(rev_text_dict_val['review']['id'])\n                                    review_text_list.append(rev_text_dict_val['review']['review_text'])\n                                    review_rating_list.append(rev_text_dict_val['review']['rating'])                        \n\n                        resto_index = resto_index+1 \n        except KeyError:\n            pass",
            "execution_count": 15,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def exhaustiveSearch(city_id,collection_id,collection_res_count):\n    '''\n    The basic call to SEARCH API of ZOMATO\n    API allows retrieving only upto 20 results at a time so we iterate in same collection till all restaurants obtained\n    '''\n    start = 0\n    cnt = 20\n    resto_index = 0\n    offset = start\n    \n    output = search(city_id,collection_id,start=offset,count=cnt)\n    if (checkKey(output,'results_shown') == 1):\n        total_results = output['results_shown']\n        #print(\"results_shown = \", total_results)\n        #print(\"collection_res_count = \",collection_res_count)\n\n        if total_results == collection_res_count: #1st extraction itself gave all restaurants\n            #print(\"ONLY 1 CALL ENOUGH to get all restaurants\")        \n            extract_resto_and_reviews(collection_id,output,total_results)               \n        else:\n            #print(\"WILL BE DOING MORE CALLS to get all restaurants\")\n            extract_resto_and_reviews(collection_id,output,total_results) #1st extraction as is since output is already obtained above \n\n            offset = start+total_results #determine new offset for next search\n\n            while (offset <=collection_res_count):\n                #print(\"offset=\",offset)\n                output = search(city_id,collection_id,start=offset,count=cnt)\n                if (checkKey(output,'results_shown') == 1):\n                    total_results = output['results_shown']\n                    print(\"new results_shown = \", total_results)\n\n                    extract_resto_and_reviews(collection_id,output,total_results)\n\n                    offset = offset+total_results #determine new offset for next search\n                    if(total_results == 0): #no more results coming\n                        print(\"no more restaurants data to fetch\")\n                        break\n                else:\n                    print(\"no results found in this iteration\")\n                    \n        all_review_data = {'rest_id':review_rest_id_list,'review_id':review_id_list, \n                           'review_text':review_text_list,'review_rating':review_rating_list}\n        all_resto_data = {'collection_id':collection_id_list,'rest_id':rest_id_list, \n                      'rest_name':rest_name_list,'rest_locality':rest_locality_list,\n                      'rest_user_rating':rest_user_rating_list}\n    else:\n        print(\"no results found in this iteration\")\n        \n        all_review_data = {'rest_id':review_rest_id_list,'review_id':review_id_list, \n                           'review_text':review_text_list,'review_rating':review_rating_list}\n        all_resto_data = {'collection_id':collection_id_list,'rest_id':rest_id_list, \n                      'rest_name':rest_name_list,'rest_locality':rest_locality_list,\n                      'rest_user_rating':rest_user_rating_list}\n    return(all_resto_data,all_review_data)",
            "execution_count": 96,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def upload_file(file_from, file_to):\n    '''Optionally you can export pandas data to a dropbox for reviewing independtly on your PC use your DROPBOX API key in below function'''\n    dbx = dropbox.Dropbox(\"JRedVn3NSbAAAAAAAAAAOkLdmz1jtZnNfjqfaOJMPsZ_P9o5yi325Lug4oNUI5P1\")\n    f = open(file_from, 'rb')\n    dbx.files_upload(f.read(), file_to) ",
            "execution_count": 113,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## The MAIN code processing begins from here"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "if __name__ == \"__main__\":\n    api_key = \"19b2c1a3c8e2493d77b2231b99696407\"\n    headers = initialize(api_key)\n\n    user_location=input(\"Enter location:\")\n    #user_location=\"Mumbai\"\n    location_result = getLocation(user_location)\n    #print(location_result)\n    \n    collection_list = getCollections(str(location_result['city_id']))",
            "execution_count": 86,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Enter location:Mumbai\nlocation found\ncollections found \n"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#collection_list",
            "execution_count": 87,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_collections = pd.DataFrame.from_dict(json_normalize(collection_list), orient='columns')",
            "execution_count": 88,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_collections.shape",
            "execution_count": 89,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 89,
                    "data": {
                        "text/plain": "(50, 7)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "new_columns={'collection.collection_id':'collection_id','collection.description':'description','collection.res_count':'res_count','collection.title':'title'}\nunwanted_columns=['collection.image_url','collection.share_url','collection.url']\ndf_collections = df_collections.rename(columns=new_columns)\ndf_collections = df_collections.drop(columns=unwanted_columns,axis=1)",
            "execution_count": 90,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_collections.head()",
            "execution_count": 91,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 91,
                    "data": {
                        "text/plain": "   collection_id                                        description  \\\n0              1         Most popular restaurants in town this week   \n1         274852  The hunt for the highest-rated restaurants in ...   \n2             29                        The best new places in town   \n3         304361                               Binge. Chug. Groove!   \n4              4  The most idyllic outdoor-dining spots in the city   \n\n   res_count                                              title  \n0         30                                 Trending This Week  \n1        233                                Great Food, No Bull  \n2         25                                       Newly Opened  \n3         15   Mumbai's Best Food & Party Destination - The Orb  \n4         22                                    Outdoor Seating  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>collection_id</th>\n      <th>description</th>\n      <th>res_count</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Most popular restaurants in town this week</td>\n      <td>30</td>\n      <td>Trending This Week</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>274852</td>\n      <td>The hunt for the highest-rated restaurants in ...</td>\n      <td>233</td>\n      <td>Great Food, No Bull</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29</td>\n      <td>The best new places in town</td>\n      <td>25</td>\n      <td>Newly Opened</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>304361</td>\n      <td>Binge. Chug. Groove!</td>\n      <td>15</td>\n      <td>Mumbai's Best Food &amp; Party Destination - The Orb</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>The most idyllic outdoor-dining spots in the city</td>\n      <td>22</td>\n      <td>Outdoor Seating</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## We have now collected all the collections & I will only fetch data for first 8 collections in this program"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_sample_collection = df_collections.head(8)",
            "execution_count": 97,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_sample_collection",
            "execution_count": 98,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 98,
                    "data": {
                        "text/plain": "   collection_id                                        description  \\\n0              1         Most popular restaurants in town this week   \n1         274852  The hunt for the highest-rated restaurants in ...   \n2             29                        The best new places in town   \n3         304361                               Binge. Chug. Groove!   \n4              4  The most idyllic outdoor-dining spots in the city   \n5         304866  Zomato's most searched restaurants of 2019 in ...   \n6         304503  Zomato's best openings of 2019 - the cr\u00e8me de ...   \n7             40  From cookies and doughnuts to ice cream and ca...   \n\n   res_count                                              title  \n0         30                                 Trending This Week  \n1        233                                Great Food, No Bull  \n2         25                                       Newly Opened  \n3         15   Mumbai's Best Food & Party Destination - The Orb  \n4         22                                    Outdoor Seating  \n5         17                                 Most Searched 2019  \n6         19                              Best Openings of 2019  \n7         86                                        Sweet Tooth  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>collection_id</th>\n      <th>description</th>\n      <th>res_count</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Most popular restaurants in town this week</td>\n      <td>30</td>\n      <td>Trending This Week</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>274852</td>\n      <td>The hunt for the highest-rated restaurants in ...</td>\n      <td>233</td>\n      <td>Great Food, No Bull</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29</td>\n      <td>The best new places in town</td>\n      <td>25</td>\n      <td>Newly Opened</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>304361</td>\n      <td>Binge. Chug. Groove!</td>\n      <td>15</td>\n      <td>Mumbai's Best Food &amp; Party Destination - The Orb</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>The most idyllic outdoor-dining spots in the city</td>\n      <td>22</td>\n      <td>Outdoor Seating</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>304866</td>\n      <td>Zomato's most searched restaurants of 2019 in ...</td>\n      <td>17</td>\n      <td>Most Searched 2019</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>304503</td>\n      <td>Zomato's best openings of 2019 - the cr\u00e8me de ...</td>\n      <td>19</td>\n      <td>Best Openings of 2019</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>40</td>\n      <td>From cookies and doughnuts to ice cream and ca...</td>\n      <td>86</td>\n      <td>Sweet Tooth</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Creating dataframe objects to hold review & restaurant data"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_reviews = pd.DataFrame(columns = ['rest_id', 'review_id','review_text','review_rating'])\ndf_restaurant = pd.DataFrame(columns = ['collection_id','rest_id', 'rest_name','rest_locality','rest_user_rating'])",
            "execution_count": 99,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## For every collection we get all restos & their reviews"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "for index in df_sample_collection.index: #loop over each collection (4 for now)\n    all_review_data = {}\n    all_resto_data = {}\n    rest_id_list = []\n    rest_name_list = []\n    rest_locality_list = []\n    rest_user_rating_list = []\n    collection_id_list = []\n    review_rest_id_list = []\n    review_id_list = []  \n    review_text_list = []\n    review_rating_list = []\n    \n    coll_res_count = df_sample_collection['res_count'][index]\n    print(\"processing collection = \",df_sample_collection['collection_id'][index])\n    \n    all_resto_data,all_review_data = exhaustiveSearch(str(location_result['city_id']),str(df_sample_collection['collection_id'][index]),coll_res_count)\n    df_restaurant = df_restaurant.append(pd.DataFrame(all_resto_data),ignore_index=True) #append all resto data to a frame\n    df_reviews = df_reviews.append(pd.DataFrame(all_review_data),ignore_index=True) #append all resto data to a frame\n    print(\"\")\n\nprint(\"processed all collections\")",
            "execution_count": 100,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "processing collection =  1\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\n\nprocessing collection =  274852\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nnew results_shown =  20\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews key not found in this iteration\nnew results_shown =  20\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews key not found in this iteration\nnew results_shown =  20\nreviews key not found in this iteration\nnew results_shown =  20\nreviews key not found in this iteration\nnew results_shown =  0\nno more restaurants data to fetch\n\nprocessing collection =  29\nno results found in this iteration\n\nprocessing collection =  304361\nreviews found\nreviews key not found in this iteration\n\nprocessing collection =  4\nno results found in this iteration\n\nprocessing collection =  304866\nno results found in this iteration\n\nprocessing collection =  304503\nno results found in this iteration\n\nprocessing collection =  40\nno results found in this iteration\n\nprocessed all collections\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## We have now collected restaurant and review data in pandas"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## There is possibility that a restaurant might be scanned in multiple collections for purpose of further analysis lets remove duplicates"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_resto_orig = df_restaurant.copy()\ndf_review_orig = df_reviews.copy()",
            "execution_count": 101,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_resto_orig.shape",
            "execution_count": 102,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 102,
                    "data": {
                        "text/plain": "(82, 5)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_review_orig.shape",
            "execution_count": 103,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 103,
                    "data": {
                        "text/plain": "(298, 4)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#df_restaurant = df_restaurant.sort_values(\"rest_id\", inplace = True) \n#df_reviews = df_reviews.sort_values(\"review_id\", inplace = True) \n\ndf_restaurant = df_restaurant.drop_duplicates(subset = 'rest_id', keep='first')\ndf_restaurant = df_restaurant.reset_index(drop=True)\n\ndf_reviews = df_reviews.drop_duplicates(subset = 'review_id', keep='first')\ndf_reviews = df_reviews.reset_index(drop=True)",
            "execution_count": 107,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_restaurant.shape",
            "execution_count": 108,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 108,
                    "data": {
                        "text/plain": "(81, 5)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_reviews.shape",
            "execution_count": 109,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 109,
                    "data": {
                        "text/plain": "(293, 4)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_restaurant.head()",
            "execution_count": 110,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 110,
                    "data": {
                        "text/plain": "  collection_id   rest_id                 rest_name  \\\n0             1  19296768          Mitron At George   \n1             1  19294334       Bora Bora Duty Free   \n2             1  18969541                 High Jack   \n3             1  19289844  KPJ - Veg. Kitchen & Bar   \n4             1  19281880              Queen's Deck   \n\n               rest_locality rest_user_rating  \n0                       Fort              3.9  \n1  Linking Road, Bandra West              3.6  \n2      Versova, Andheri West              4.0  \n3             Kandivali East              4.0  \n4                 Churchgate              3.7  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>collection_id</th>\n      <th>rest_id</th>\n      <th>rest_name</th>\n      <th>rest_locality</th>\n      <th>rest_user_rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>19296768</td>\n      <td>Mitron At George</td>\n      <td>Fort</td>\n      <td>3.9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>19294334</td>\n      <td>Bora Bora Duty Free</td>\n      <td>Linking Road, Bandra West</td>\n      <td>3.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>18969541</td>\n      <td>High Jack</td>\n      <td>Versova, Andheri West</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>19289844</td>\n      <td>KPJ - Veg. Kitchen &amp; Bar</td>\n      <td>Kandivali East</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>19281880</td>\n      <td>Queen's Deck</td>\n      <td>Churchgate</td>\n      <td>3.7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_restaurant.to_csv('restaurant.csv', header=True)\ndf_reviews.to_csv('reviews.csv', header=True)",
            "execution_count": 111,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "file1_from = 'restaurant.csv'\nfile1_to = '/DataScience/restaurant.csv'\nfile2_from = 'reviews.csv'\nfile2_to = '/DataScience/reviews.csv'\n\ntry:\n    upload_file(file1_from,file1_to)\n    upload_file(file2_from,file2_to)\nexcept:\n    pass",
            "execution_count": 115,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#df_restaurant['rest_id'].value_counts()",
            "execution_count": 116,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#df_reviews['review_id'].value_counts()",
            "execution_count": 117,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Now we will be importing libraries needed for NLP like NLTK, Text Blob, Spacy"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import nltk\nimport re\nimport unicodedata\nimport contractions\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import sent_tokenize\nfrom textblob import TextBlob\nfrom num2words import num2words",
            "execution_count": 118,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "nltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('brown')\nnltk.download('averaged_perceptron_tagger')",
            "execution_count": 119,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/dsxuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /home/dsxuser/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /home/dsxuser/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package brown to /home/dsxuser/nltk_data...\n[nltk_data]   Package brown is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/dsxuser/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n",
                    "name": "stderr"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 119,
                    "data": {
                        "text/plain": "True"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "stopword = stopwords.words('english')\nstopword.extend([\"rated\",\"rating\",\"charge\",\"charges\",\"bill\",\"gst\",\"service\",\"visited\",\"again\",\"repeat\",\"cost\",\"friend\",\"place\",\"ambience\"])",
            "execution_count": 120,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Defining function for each task in NLP pre-processing"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def to_lowercase(text):\n    return text.lower()",
            "execution_count": 121,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def remove_html(text):\n    text = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0\u20139@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0\u20139@:%_\\+.~#?&//=]*)', '', text, flags=re.MULTILINE) # to remove links that start with HTTP/HTTPS in the tweet\n    text = re.sub(r'[-a-zA-Z0\u20139@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0\u20139@:%_\\+.~#?&//=]*)', '', text, flags=re.MULTILINE) # to remove other url links\n    \n    return text",
            "execution_count": 122,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def remove_hastags_mentions(text):\n    text = re.sub(r\"#(\\w+)\", ' ', text, flags=re.MULTILINE) #to remove hastags\n    text = re.sub(r\"@(\\w+)\", ' ', text, flags=re.MULTILINE) # to remove mentions\n    return text",
            "execution_count": 123,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def remove_emoji(text):\n    '''func to remove emoji & symbols'''\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    return text",
            "execution_count": 124,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def remove_punctuations(text):\n    punctuations = '''!()-![]{};:+'\"\\,<>/?@#$%^&*_~'''\n    text = ''.join([i for i in text if not i in punctuations]) # to remove punctuations except .\n    return text",
            "execution_count": 125,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def remove_contractions(text):\n    '''func to convert contractions to full words e.g. can't will become cannot'''\n    return ' '.join([contractions.fix(word) for word in text.split()])",
            "execution_count": 126,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def replace_ordinal_numbers(text):\n    re_results = re.findall('(\\d+(st|nd|rd|th))', text)\n    for enitre_result, suffix in re_results:\n        num = int(enitre_result[:-2])\n        text = text.replace(enitre_result, num2words(num, ordinal=True))\n    return text",
            "execution_count": 127,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def remove_numbers(text):\n    return ''.join(c for c in text if not c.isdigit())",
            "execution_count": 128,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def remove_stopwords(text):\n    word_tokens = nltk.word_tokenize(text)\n    text = ' '.join([word for word in word_tokens if word not in stopword])\n    return text",
            "execution_count": 129,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def lemmatize(text):\n    wordnet_lemmatizer = WordNetLemmatizer()\n    word_tokens = nltk.word_tokenize(text)\n    text = ' '.join([wordnet_lemmatizer.lemmatize(word) for word in word_tokens])\n    return text",
            "execution_count": 130,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def clean_review(text,is_Lower=True,remove_links=True,remove_hash_mentions=True,remove_emojis=True,\n                 remove_punct=True,remove_cont=True,remove_ordinals=True,remove_nos=True,remove_stop=True,\n                 is_lemma=True):\n    '''\n    func to pre-process the review text. You can toggle a param if you dont want particular pre-processing task to happen\n    '''\n    if is_Lower:\n        text = to_lowercase(text)\n    if remove_links:\n        text= remove_html(text)\n    if remove_hash_mentions:\n        text=remove_hastags_mentions(text)\n    if remove_emojis:\n        text= remove_emoji(text)\n    if remove_punct:\n        text= remove_punctuations(text)\n    if remove_cont:\n        text= remove_contractions(text)\n    if remove_ordinals:\n        text= replace_ordinal_numbers(text)\n    if remove_nos:\n        text= remove_numbers(text)\n    if remove_stop:\n        text= remove_stopwords(text)\n    if is_lemma:\n        text= lemmatize(text)\n    \n    return (text)    ",
            "execution_count": 131,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def get_ngram_noun_phrases(sentence, ngrams = 2):\n    '''\n    func to get all noun phrases using Text Blob. A dish name might be all nouns but could be a 2 letter word or 3 or 4 or 5\n    this will extract all noun phrases from the review's blob objects and put in a list\n    '''\n    sent_blob = TextBlob(str(sentence))\n    ngram_list = sent_blob.ngrams(n=ngrams)   \n    #print(ngram_list)\n    #print(\"\")\n    for pair in ngram_list:\n        ngram = ' '.join(pair)\n        word_blob = TextBlob(ngram)\n        \n        for np in word_blob.noun_phrases:\n            #print(np)\n            if np not in noun_phrases_list:\n                noun_phrases_list.append(np)",
            "execution_count": 132,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def generate_noun_phrases(rev_blob):\n    '''\n    func to generate all noun phrases from a blob object\n    '''\n    for sent in rev_blob.sentences:   \n        get_ngram_noun_phrases(sent,2) #bigram phrases\n        get_ngram_noun_phrases(sent,3) #trigram phrases\n        get_ngram_noun_phrases(sent,4) \n        get_ngram_noun_phrases(sent,5)",
            "execution_count": 133,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def generate_possible_menu_list(noun_phrases_list):\n    '''\n    func that will create a list where the noun phrase contains all nouns which means its a possible dish name\n    '''\n    for element in noun_phrases_list:\n        tag_list = []\n        phrase_blob = TextBlob(element)\n        tag_list = phrase_blob.tags\n        #print(\"tag_list \",tag_list)\n        if ((tag_list[0][1] == 'NN' or tag_list[0][1] == 'NNS') and (tag_list[-1][1] == 'NN' or tag_list[-1][1] == 'NNS')):\n            possible_menu_list.append(element)",
            "execution_count": 134,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def remove_duplicate_noun_phrases(possible_menu_list):\n    '''\n    We could get similar dish names while parsing each noun phrase\n    e.g. chicken noodles vs spicy chicken noodles. In such cases will keep only the phrase with longest length\n    '''\n    for i, elements in enumerate(possible_menu_list):\n        try:\n            thiselem = str(elements)\n            matching_elements = [s for s in possible_menu_list if thiselem in s]\n            #print(matching_elements)\n            for j, val in enumerate(matching_elements):\n                curr_val = str(val)\n                next_val = str(matching_elements[(j + 1) % len(matching_elements)])\n\n                if len(curr_val) > len(next_val):\n                    #print(\"Removing \",next_val)\n                    if next_val not in exclude_list:\n                        exclude_list.append(next_val)\n                elif len(curr_val) < len(next_val):\n                    #print(\"Removing \",curr_val)\n                    if curr_val not in exclude_list:\n                        exclude_list.append(curr_val)\n        except:\n            pass\n    \n    for x in exclude_list:\n        try:\n            possible_menu_list.remove(x)\n        except:\n            pass",
            "execution_count": 135,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def sentiment_textblob(feedback): \n    '''\n    func to map the sentence polarity to a user defined sentiment label\n    '''\n    senti = TextBlob(feedback) \n    polarity = senti.sentiment.polarity \n    if -1 <= polarity < -0.5: \n        label = 'very bad' \n    elif -0.5 <= polarity < -0.1: \n        label = 'bad' \n    elif -0.1 <= polarity < 0.2: \n        label = 'ok' \n    elif 0.2 <= polarity < 0.6: \n        label = 'good' \n    elif 0.6 <= polarity <= 1: \n        label = 'best' \n    \n    return (polarity, label) ",
            "execution_count": 136,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def analyze_review_to_get_menu_and_sentiment(id,text):\n    '''\n    func to analyze each review text\n    1. Convert to a BLOB\n    2. Get noun phrases using bigrams, trigrams, quadgrams and so on\n    3. Get possible menu list items (all nouns POS)\n    4. Retain menu items(phrase) with max length i.e. remove duplicates\n    5. Search each item with each sentence of the given review text and if found\n       a. Get sentiment score, label of that sentence\n       b. break\n       c. Store in list for adding to a pandas frame\n    '''\n    \n    '''is_Lower=True,remove_links=True,remove_hash_mentions=True,remove_emoji=True,\n       remove_punct=True,remove_cont=True,remove_ordinals=True,remove_nos=True,remove_stop=True,\n       is_lemma=True\n    '''\n    \n    cl_review = clean_review(text,True,True,True,True,True,True,True,True,True,True)\n    cl_review_s = clean_review(text,True,True,True,True,True,True,True,True,True,True)\n    \n    rev_blob = TextBlob(cl_review)\n    rev_blob_s = TextBlob(cl_review_s)\n        \n    generate_noun_phrases(rev_blob)\n    #print(\"noun_phrases_list = \", noun_phrases_list)\n    \n    generate_possible_menu_list(noun_phrases_list)\n    #print(\"possible menu_list = \",possible_menu_list) \n    \n    remove_duplicate_noun_phrases(possible_menu_list)\n    #print(\"possible menu_list after duplicates removal=\",possible_menu_list)\n    \n    raw_sentence_list = sent_tokenize(str(rev_blob_s))\n    \n    detected_sentence = ''\n    polarity= -99 \n    label = ''\n    for m in possible_menu_list:\n        for sentence in raw_sentence_list:\n            if m in sentence:\n                (polarity, label) = sentiment_textblob(str(sentence))\n               \n                detected_sentence = sentence\n                break\n        res_id_list.append(id)\n        menu_item_list.append(m)\n        detected_sentence_list.append(detected_sentence)\n        sent_polarity_list.append(polarity)\n        sentiment_label_list.append(label)",
            "execution_count": 137,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Temporary code to read data files directly from dropbox"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#dbx = dropbox.Dropbox(\"JRedVn3NSbAAAAAAAAAAMp2Oi22PT1ZquPWWryIlgXIEFaI6cO_IlyjxClMv2xLp\")\n#with open(\"reviews.csv\", \"wb\") as f:\n#    metadata, res = dbx.files_download(path=\"/DataScience/reviews.csv\")\n#    f.write(res.content)",
            "execution_count": 138,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#with open(\"restaurant.csv\", \"wb\") as f:\n#    metadata, res = dbx.files_download(path=\"/DataScience/restaurant.csv\")\n#    f.write(res.content)",
            "execution_count": 139,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#df_reviews = pd.read_csv(\"reviews.csv\")\n#df_restaurant = pd.read_csv('restaurant.csv')",
            "execution_count": 140,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_reviews['clean_review_text'] = df_reviews.review_text.apply(clean_review)",
            "execution_count": 141,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_reviews.head()",
            "execution_count": 142,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 142,
                    "data": {
                        "text/plain": "    rest_id review_id                                        review_text  \\\n0  19296768  47205382  MITRON is a new place thats opened up in Fort,...   \n1  19296768  47149493  Our bill was around 6k which was inclusive of ...   \n2  19296768  47112378  The place has newly opened. The ambience is re...   \n3  19296768  47101566  From serving one of the best pizzas in town to...   \n4  19294334  47274716                      Loved the pizza and the baos!   \n\n  review_rating                                  clean_review_text  \n0             5  mitron new opened fort mustvisit . good food g...  \n1             2  around k inclusive bomb \u20b9 authority ask waive ...  \n2             5  newly opened . really good comfortable sitting...  \n3             5  serving one best pizza town range quirky pocke...  \n4             5                                   loved pizza baos  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rest_id</th>\n      <th>review_id</th>\n      <th>review_text</th>\n      <th>review_rating</th>\n      <th>clean_review_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19296768</td>\n      <td>47205382</td>\n      <td>MITRON is a new place thats opened up in Fort,...</td>\n      <td>5</td>\n      <td>mitron new opened fort mustvisit . good food g...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19296768</td>\n      <td>47149493</td>\n      <td>Our bill was around 6k which was inclusive of ...</td>\n      <td>2</td>\n      <td>around k inclusive bomb \u20b9 authority ask waive ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19296768</td>\n      <td>47112378</td>\n      <td>The place has newly opened. The ambience is re...</td>\n      <td>5</td>\n      <td>newly opened . really good comfortable sitting...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19296768</td>\n      <td>47101566</td>\n      <td>From serving one of the best pizzas in town to...</td>\n      <td>5</td>\n      <td>serving one best pizza town range quirky pocke...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19294334</td>\n      <td>47274716</td>\n      <td>Loved the pizza and the baos!</td>\n      <td>5</td>\n      <td>loved pizza baos</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Now we will be merging reviews(rating 3 and above) into single review text per restaurant"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_merged_reviews = pd.DataFrame(columns = ['rest_id','review_text'])\nres_id_list = []\nmerged_reviews_list = []\nold_rest_id = 0\ncurr_rest_id = 0\ntemp_text = ''\nfor index in df_reviews.index:\n    if int(df_reviews['review_rating'][index]) >=3:\n        cleaned_review = df_reviews['review_text'][index]\n        curr_rest_id = df_reviews['rest_id'][index]\n        #print(curr_rest_id)\n        if old_rest_id == 0 or old_rest_id == curr_rest_id: #1st iteration or same restaurant so joining cleaned reviews\n            if temp_text == '':\n                temp_text = temp_text+cleaned_review\n            else:\n                temp_text = temp_text+'.'+cleaned_review\n        else:\n            res_id_list.append(old_rest_id)\n            merged_reviews_list.append(temp_text)\n            temp_text = ''\n            old_rest_id = 0\n            curr_rest_id = 0\n            if temp_text == '':\n                temp_text = temp_text+cleaned_review\n            else:\n                temp_text = temp_text+'.'+cleaned_review\n\n        old_rest_id = curr_rest_id\n\nres_id_list.append(curr_rest_id) #from last iteration\nmerged_reviews_list.append(temp_text) #from last iteration\n\nall_cleaned_review_data = {'rest_id':res_id_list,'review_text':merged_reviews_list}\ndf_merged_reviews = df_merged_reviews.append(pd.DataFrame(all_cleaned_review_data),ignore_index=True)",
            "execution_count": 143,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_merged_reviews.head()",
            "execution_count": 144,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 144,
                    "data": {
                        "text/plain": "    rest_id                                        review_text\n0  19296768  MITRON is a new place thats opened up in Fort,...\n1  19294334  Loved the pizza and the baos!.Soo soothing & S...\n2  18969541  Amazing experience!.Great experience!.really l...\n3  19289844  KPJ - Veg. Kitchen & Bar.....  Khao Piyo Jiyo ...\n4  19281880  I consider myself somewhat of a tea aficionado...",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rest_id</th>\n      <th>review_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19296768</td>\n      <td>MITRON is a new place thats opened up in Fort,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19294334</td>\n      <td>Loved the pizza and the baos!.Soo soothing &amp; S...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18969541</td>\n      <td>Amazing experience!.Great experience!.really l...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19289844</td>\n      <td>KPJ - Veg. Kitchen &amp; Bar.....  Khao Piyo Jiyo ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19281880</td>\n      <td>I consider myself somewhat of a tea aficionado...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#df_merged_reviews['review_text'][0]",
            "execution_count": 145,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Processing all reviews from reviews frame and store in new frame"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_analyzed_reviews = pd.DataFrame(columns = ['rest_id','menu_item','sentiment_score','sentiment_label','what_people_said'])\nfor index in df_merged_reviews.index: #loop over each review\n    \n    res_id_list = []\n    menu_item_list = []\n    detected_sentence_list = []\n    sent_polarity_list = []\n    sentiment_label_list = []\n    \n    noun_phrases_list = []\n    possible_menu_list = []\n    exclude_list = []\n    raw_sentence_list=[]\n    \n    analyze_review_to_get_menu_and_sentiment(df_merged_reviews['rest_id'][index],str(df_merged_reviews['review_text'][index]))\n    \n    #print(menu_item_list)\n    #print(sent_polarity_list)\n    #print(sentiment_label_list)\n    #print(detected_sentence_list)\n    #break\n    \n    all_cleaned_review_data = {'rest_id':res_id_list, 'menu_item':menu_item_list,'sentiment_score':sent_polarity_list,\n                           'sentiment_label':sentiment_label_list,'what_people_said':detected_sentence_list}\n\n    df_analyzed_reviews = df_analyzed_reviews.append(pd.DataFrame(all_cleaned_review_data),ignore_index=True) #append all analyzed review data to a frame\n\nprint(\"processed all reviews\")",
            "execution_count": 146,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "processed all reviews\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "df_analyzed_reviews",
            "execution_count": 147,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 147,
                    "data": {
                        "text/plain": "       rest_id                               menu_item  sentiment_score  \\\n0     19296768                          fort mustvisit         0.136364   \n1     19296768                        cocktail sheesha         0.525000   \n2     19296768                       rocket leaf salad         0.300000   \n3     19296768            paneer starter peri peri fry         0.150000   \n4     19296768                           cinnamon star         0.600000   \n5     19296768                              star anise         0.600000   \n6     19296768                            course lemon         0.038095   \n7     19296768                    perfection succulent         0.038095   \n8     19296768                            amount lemon         0.038095   \n9     19296768      fire bowl streetstyle chinese dish         0.300000   \n10    19296768         wrap experience caramel custard         0.000000   \n11    19296768                      vibe f.r.i e.n d.s         0.000000   \n12    19296768                         mitron triangle         0.700000   \n13    19296768                           triangle good         0.700000   \n14    19296768                             corn cheese         0.700000   \n15    19296768                        pav bhaji fondue         1.000000   \n16    19296768                   quality quantity food         0.487500   \n17    19296768                              visit sobo         0.142273   \n18    19296768          pizza town range quirky pocket         0.142273   \n19    19296768        cocktail kala base pizza lasooni         0.142273   \n20    19296768         pork burger brain bain cocktail         0.362121   \n21    19294334                          pizza baos.soo         0.700000   \n22    19294334                  it.ambience drink food         0.700000   \n23    19294334                         waterfield road         0.263889   \n24    19294334                           alchohol duty         0.263889   \n25    19294334                               indoor ac         0.263889   \n26    19294334                              section dj         0.263889   \n27    19294334                          bora bora duty         0.263889   \n28    19294334          burger pizza kitchenlive sushi         0.263889   \n29    19294334        concept swipe card counter order         0.263889   \n...        ...                                     ...              ...   \n1831  18962112                 challenge cutlery skill         0.000000   \n1832  18962112               portion hummus pita bread         0.166667   \n1833  18962112                              kebab meat         0.000000   \n1834  18962112                               charm bit         0.200000   \n1835  18962112      mint tahini sauce compliment kebab         0.200000   \n1836  18962112                             hamid prawn         0.150000   \n1837  18962112                             prawn prawn         0.150000   \n1838  18962112                               kuzu rice         0.050000   \n1839  18962112          rice staple food asian country         0.050000   \n1840  18962112          staple food asian country meal         0.050000   \n1841  18962112                     pistachio mint rice         0.000000   \n1842  18962112                   babaganoush margarita         0.500000   \n1843  18962112                           taste justice         0.500000   \n1844  18962112                       level consistency         0.160000   \n1845  18962112                signature brand bayroute         0.160000   \n1846  18962112                          tea disappoint         0.000000   \n1847  18962112                           eyecatchy lot         0.000000   \n1848  18962112                     highlight afternoon         0.000000   \n1849  18962112                        smoky rum raisin         0.433333   \n1850  18962112  prominence flavour sulemani chai smoke         0.433333   \n1851  18962112                             fan dessert         0.400000   \n1852  18962112                       highlight dessert         0.600000   \n1853  18962112                            taste outlet         0.250000   \n1854  18962112               chocolate fondant portion         0.163333   \n1855  18962112                         lunch high note         0.163333   \n1856  18962112                         chocolate berry         0.500000   \n1857  18962112            almond honey crush ice cream         0.500000   \n1858  18962112                        restaurant price         0.152778   \n1859  18962112       level professionalism consistency         0.330000   \n1860  18962112                         attitude outlet         0.375000   \n\n     sentiment_label                                   what_people_said  \n0                 ok                 mitron new opened fort mustvisit .  \n1               good  good food great interior really nice cocktail ...  \n2               good          started rocket leaf salad totally worth .  \n3                 ok  post healthy start pan fried paneer starter pe...  \n4               best   amazing cocktail flavoured cinnamon star anise .  \n5               best   amazing cocktail flavoured cinnamon star anise .  \n6                 ok  main course lemon marinated grilled chicken gr...  \n7                 ok  main course lemon marinated grilled chicken gr...  \n8                 ok  main course lemon marinated grilled chicken gr...  \n9               good  fire bowl streetstyle chinese dish really quit...  \n10                ok  wrap experience caramel custard made perfection .  \n11                ok                          give vibe f.r.i e.n d.s .  \n12              best  mitron triangle good like patti samosa stuffed...  \n13              best  mitron triangle good like patti samosa stuffed...  \n14              best  mitron triangle good like patti samosa stuffed...  \n15              best                   pav bhaji fondue must one best .  \n16              good  also quite pocket friendly according quality q...  \n17                ok  dj start playing post serving one best pizza t...  \n18                ok  dj start playing post serving one best pizza t...  \n19                ok  dj start playing post serving one best pizza t...  \n20              good  pulled pork burger brain bain cocktail first p...  \n21              best           loved pizza baos.soo soothing seducing .  \n22              best                     loved it.ambience drink food .  \n23              good  bora bora duty free restaurant alert located w...  \n24              good  bora bora duty free restaurant alert located w...  \n25              good  bora bora duty free restaurant alert located w...  \n26              good  bora bora duty free restaurant alert located w...  \n27              good  bora bora duty free restaurant alert located w...  \n28              good  bora bora duty free restaurant alert located w...  \n29              good  bora bora duty free restaurant alert located w...  \n...              ...                                                ...  \n1831              ok                     dish challenge cutlery skill .  \n1832              ok                 decent portion hummus pita bread .  \n1833              ok             istanbuli kebab meat properly cooked .  \n1834            good  mint tahini sauce compliment kebab like charm ...  \n1835            good  mint tahini sauce compliment kebab like charm ...  \n1836              ok   hamid prawn prawn fresh crispy properly cooked .  \n1837              ok   hamid prawn prawn fresh crispy properly cooked .  \n1838              ok  machboos al kuzu rice staple food asian countr...  \n1839              ok  machboos al kuzu rice staple food asian countr...  \n1840              ok  machboos al kuzu rice staple food asian countr...  \n1841              ok              personally like pistachio mint rice .  \n1842            good  babaganoush margarita although look fabulous t...  \n1843            good  babaganoush margarita although look fabulous t...  \n1844              ok  turkish madness one signature brand bayroute m...  \n1845              ok  turkish madness one signature brand bayroute m...  \n1846              ok                      turkish iced tea disappoint .  \n1847              ok  sumac delight strongest eyecatchy lot drink qu...  \n1848              ok  sumac delight strongest eyecatchy lot drink qu...  \n1849            good  smoky rum raisin although drink strong could f...  \n1850            good  smoky rum raisin although drink strong could f...  \n1851            good                         baklava huge fan dessert .  \n1852            best          popular choice around highlight dessert .  \n1853            good                          consistent taste outlet .  \n1854              ok  chocolate fondant portion decent yet taste end...  \n1855              ok  chocolate fondant portion decent yet taste end...  \n1856            good  almond honey crush ice cream prominent tasted ...  \n1857            good  almond honey crush ice cream prominent tasted ...  \n1858              ok  authentic restaurant price maybe hard pocket a...  \n1859            good  notable mention high level professionalism con...  \n1860            good  however staff friendly arrogant attitude outle...  \n\n[1861 rows x 5 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rest_id</th>\n      <th>menu_item</th>\n      <th>sentiment_score</th>\n      <th>sentiment_label</th>\n      <th>what_people_said</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19296768</td>\n      <td>fort mustvisit</td>\n      <td>0.136364</td>\n      <td>ok</td>\n      <td>mitron new opened fort mustvisit .</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19296768</td>\n      <td>cocktail sheesha</td>\n      <td>0.525000</td>\n      <td>good</td>\n      <td>good food great interior really nice cocktail ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19296768</td>\n      <td>rocket leaf salad</td>\n      <td>0.300000</td>\n      <td>good</td>\n      <td>started rocket leaf salad totally worth .</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19296768</td>\n      <td>paneer starter peri peri fry</td>\n      <td>0.150000</td>\n      <td>ok</td>\n      <td>post healthy start pan fried paneer starter pe...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19296768</td>\n      <td>cinnamon star</td>\n      <td>0.600000</td>\n      <td>best</td>\n      <td>amazing cocktail flavoured cinnamon star anise .</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>19296768</td>\n      <td>star anise</td>\n      <td>0.600000</td>\n      <td>best</td>\n      <td>amazing cocktail flavoured cinnamon star anise .</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>19296768</td>\n      <td>course lemon</td>\n      <td>0.038095</td>\n      <td>ok</td>\n      <td>main course lemon marinated grilled chicken gr...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>19296768</td>\n      <td>perfection succulent</td>\n      <td>0.038095</td>\n      <td>ok</td>\n      <td>main course lemon marinated grilled chicken gr...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>19296768</td>\n      <td>amount lemon</td>\n      <td>0.038095</td>\n      <td>ok</td>\n      <td>main course lemon marinated grilled chicken gr...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>19296768</td>\n      <td>fire bowl streetstyle chinese dish</td>\n      <td>0.300000</td>\n      <td>good</td>\n      <td>fire bowl streetstyle chinese dish really quit...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>19296768</td>\n      <td>wrap experience caramel custard</td>\n      <td>0.000000</td>\n      <td>ok</td>\n      <td>wrap experience caramel custard made perfection .</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>19296768</td>\n      <td>vibe f.r.i e.n d.s</td>\n      <td>0.000000</td>\n      <td>ok</td>\n      <td>give vibe f.r.i e.n d.s .</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>19296768</td>\n      <td>mitron triangle</td>\n      <td>0.700000</td>\n      <td>best</td>\n      <td>mitron triangle good like patti samosa stuffed...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>19296768</td>\n      <td>triangle good</td>\n      <td>0.700000</td>\n      <td>best</td>\n      <td>mitron triangle good like patti samosa stuffed...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>19296768</td>\n      <td>corn cheese</td>\n      <td>0.700000</td>\n      <td>best</td>\n      <td>mitron triangle good like patti samosa stuffed...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>19296768</td>\n      <td>pav bhaji fondue</td>\n      <td>1.000000</td>\n      <td>best</td>\n      <td>pav bhaji fondue must one best .</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>19296768</td>\n      <td>quality quantity food</td>\n      <td>0.487500</td>\n      <td>good</td>\n      <td>also quite pocket friendly according quality q...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>19296768</td>\n      <td>visit sobo</td>\n      <td>0.142273</td>\n      <td>ok</td>\n      <td>dj start playing post serving one best pizza t...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19296768</td>\n      <td>pizza town range quirky pocket</td>\n      <td>0.142273</td>\n      <td>ok</td>\n      <td>dj start playing post serving one best pizza t...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19296768</td>\n      <td>cocktail kala base pizza lasooni</td>\n      <td>0.142273</td>\n      <td>ok</td>\n      <td>dj start playing post serving one best pizza t...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>19296768</td>\n      <td>pork burger brain bain cocktail</td>\n      <td>0.362121</td>\n      <td>good</td>\n      <td>pulled pork burger brain bain cocktail first p...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>19294334</td>\n      <td>pizza baos.soo</td>\n      <td>0.700000</td>\n      <td>best</td>\n      <td>loved pizza baos.soo soothing seducing .</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>19294334</td>\n      <td>it.ambience drink food</td>\n      <td>0.700000</td>\n      <td>best</td>\n      <td>loved it.ambience drink food .</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>19294334</td>\n      <td>waterfield road</td>\n      <td>0.263889</td>\n      <td>good</td>\n      <td>bora bora duty free restaurant alert located w...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>19294334</td>\n      <td>alchohol duty</td>\n      <td>0.263889</td>\n      <td>good</td>\n      <td>bora bora duty free restaurant alert located w...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>19294334</td>\n      <td>indoor ac</td>\n      <td>0.263889</td>\n      <td>good</td>\n      <td>bora bora duty free restaurant alert located w...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>19294334</td>\n      <td>section dj</td>\n      <td>0.263889</td>\n      <td>good</td>\n      <td>bora bora duty free restaurant alert located w...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>19294334</td>\n      <td>bora bora duty</td>\n      <td>0.263889</td>\n      <td>good</td>\n      <td>bora bora duty free restaurant alert located w...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>19294334</td>\n      <td>burger pizza kitchenlive sushi</td>\n      <td>0.263889</td>\n      <td>good</td>\n      <td>bora bora duty free restaurant alert located w...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>19294334</td>\n      <td>concept swipe card counter order</td>\n      <td>0.263889</td>\n      <td>good</td>\n      <td>bora bora duty free restaurant alert located w...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1831</th>\n      <td>18962112</td>\n      <td>challenge cutlery skill</td>\n      <td>0.000000</td>\n      <td>ok</td>\n      <td>dish challenge cutlery skill .</td>\n    </tr>\n    <tr>\n      <th>1832</th>\n      <td>18962112</td>\n      <td>portion hummus pita bread</td>\n      <td>0.166667</td>\n      <td>ok</td>\n      <td>decent portion hummus pita bread .</td>\n    </tr>\n    <tr>\n      <th>1833</th>\n      <td>18962112</td>\n      <td>kebab meat</td>\n      <td>0.000000</td>\n      <td>ok</td>\n      <td>istanbuli kebab meat properly cooked .</td>\n    </tr>\n    <tr>\n      <th>1834</th>\n      <td>18962112</td>\n      <td>charm bit</td>\n      <td>0.200000</td>\n      <td>good</td>\n      <td>mint tahini sauce compliment kebab like charm ...</td>\n    </tr>\n    <tr>\n      <th>1835</th>\n      <td>18962112</td>\n      <td>mint tahini sauce compliment kebab</td>\n      <td>0.200000</td>\n      <td>good</td>\n      <td>mint tahini sauce compliment kebab like charm ...</td>\n    </tr>\n    <tr>\n      <th>1836</th>\n      <td>18962112</td>\n      <td>hamid prawn</td>\n      <td>0.150000</td>\n      <td>ok</td>\n      <td>hamid prawn prawn fresh crispy properly cooked .</td>\n    </tr>\n    <tr>\n      <th>1837</th>\n      <td>18962112</td>\n      <td>prawn prawn</td>\n      <td>0.150000</td>\n      <td>ok</td>\n      <td>hamid prawn prawn fresh crispy properly cooked .</td>\n    </tr>\n    <tr>\n      <th>1838</th>\n      <td>18962112</td>\n      <td>kuzu rice</td>\n      <td>0.050000</td>\n      <td>ok</td>\n      <td>machboos al kuzu rice staple food asian countr...</td>\n    </tr>\n    <tr>\n      <th>1839</th>\n      <td>18962112</td>\n      <td>rice staple food asian country</td>\n      <td>0.050000</td>\n      <td>ok</td>\n      <td>machboos al kuzu rice staple food asian countr...</td>\n    </tr>\n    <tr>\n      <th>1840</th>\n      <td>18962112</td>\n      <td>staple food asian country meal</td>\n      <td>0.050000</td>\n      <td>ok</td>\n      <td>machboos al kuzu rice staple food asian countr...</td>\n    </tr>\n    <tr>\n      <th>1841</th>\n      <td>18962112</td>\n      <td>pistachio mint rice</td>\n      <td>0.000000</td>\n      <td>ok</td>\n      <td>personally like pistachio mint rice .</td>\n    </tr>\n    <tr>\n      <th>1842</th>\n      <td>18962112</td>\n      <td>babaganoush margarita</td>\n      <td>0.500000</td>\n      <td>good</td>\n      <td>babaganoush margarita although look fabulous t...</td>\n    </tr>\n    <tr>\n      <th>1843</th>\n      <td>18962112</td>\n      <td>taste justice</td>\n      <td>0.500000</td>\n      <td>good</td>\n      <td>babaganoush margarita although look fabulous t...</td>\n    </tr>\n    <tr>\n      <th>1844</th>\n      <td>18962112</td>\n      <td>level consistency</td>\n      <td>0.160000</td>\n      <td>ok</td>\n      <td>turkish madness one signature brand bayroute m...</td>\n    </tr>\n    <tr>\n      <th>1845</th>\n      <td>18962112</td>\n      <td>signature brand bayroute</td>\n      <td>0.160000</td>\n      <td>ok</td>\n      <td>turkish madness one signature brand bayroute m...</td>\n    </tr>\n    <tr>\n      <th>1846</th>\n      <td>18962112</td>\n      <td>tea disappoint</td>\n      <td>0.000000</td>\n      <td>ok</td>\n      <td>turkish iced tea disappoint .</td>\n    </tr>\n    <tr>\n      <th>1847</th>\n      <td>18962112</td>\n      <td>eyecatchy lot</td>\n      <td>0.000000</td>\n      <td>ok</td>\n      <td>sumac delight strongest eyecatchy lot drink qu...</td>\n    </tr>\n    <tr>\n      <th>1848</th>\n      <td>18962112</td>\n      <td>highlight afternoon</td>\n      <td>0.000000</td>\n      <td>ok</td>\n      <td>sumac delight strongest eyecatchy lot drink qu...</td>\n    </tr>\n    <tr>\n      <th>1849</th>\n      <td>18962112</td>\n      <td>smoky rum raisin</td>\n      <td>0.433333</td>\n      <td>good</td>\n      <td>smoky rum raisin although drink strong could f...</td>\n    </tr>\n    <tr>\n      <th>1850</th>\n      <td>18962112</td>\n      <td>prominence flavour sulemani chai smoke</td>\n      <td>0.433333</td>\n      <td>good</td>\n      <td>smoky rum raisin although drink strong could f...</td>\n    </tr>\n    <tr>\n      <th>1851</th>\n      <td>18962112</td>\n      <td>fan dessert</td>\n      <td>0.400000</td>\n      <td>good</td>\n      <td>baklava huge fan dessert .</td>\n    </tr>\n    <tr>\n      <th>1852</th>\n      <td>18962112</td>\n      <td>highlight dessert</td>\n      <td>0.600000</td>\n      <td>best</td>\n      <td>popular choice around highlight dessert .</td>\n    </tr>\n    <tr>\n      <th>1853</th>\n      <td>18962112</td>\n      <td>taste outlet</td>\n      <td>0.250000</td>\n      <td>good</td>\n      <td>consistent taste outlet .</td>\n    </tr>\n    <tr>\n      <th>1854</th>\n      <td>18962112</td>\n      <td>chocolate fondant portion</td>\n      <td>0.163333</td>\n      <td>ok</td>\n      <td>chocolate fondant portion decent yet taste end...</td>\n    </tr>\n    <tr>\n      <th>1855</th>\n      <td>18962112</td>\n      <td>lunch high note</td>\n      <td>0.163333</td>\n      <td>ok</td>\n      <td>chocolate fondant portion decent yet taste end...</td>\n    </tr>\n    <tr>\n      <th>1856</th>\n      <td>18962112</td>\n      <td>chocolate berry</td>\n      <td>0.500000</td>\n      <td>good</td>\n      <td>almond honey crush ice cream prominent tasted ...</td>\n    </tr>\n    <tr>\n      <th>1857</th>\n      <td>18962112</td>\n      <td>almond honey crush ice cream</td>\n      <td>0.500000</td>\n      <td>good</td>\n      <td>almond honey crush ice cream prominent tasted ...</td>\n    </tr>\n    <tr>\n      <th>1858</th>\n      <td>18962112</td>\n      <td>restaurant price</td>\n      <td>0.152778</td>\n      <td>ok</td>\n      <td>authentic restaurant price maybe hard pocket a...</td>\n    </tr>\n    <tr>\n      <th>1859</th>\n      <td>18962112</td>\n      <td>level professionalism consistency</td>\n      <td>0.330000</td>\n      <td>good</td>\n      <td>notable mention high level professionalism con...</td>\n    </tr>\n    <tr>\n      <th>1860</th>\n      <td>18962112</td>\n      <td>attitude outlet</td>\n      <td>0.375000</td>\n      <td>good</td>\n      <td>however staff friendly arrogant attitude outle...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1861 rows \u00d7 5 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Lets sort each menu item within a review in descending order of score"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_analyzed_reviews = df_analyzed_reviews.sort_values(['rest_id','sentiment_score'],ascending=[1, 0])",
            "execution_count": 148,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_analyzed_reviews.head()",
            "execution_count": 149,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 149,
                    "data": {
                        "text/plain": "    rest_id                                menu_item  sentiment_score  \\\n525   41304                         splendid evening         0.766667   \n510   41304                         group hv quality         0.640000   \n511   41304  family dinner plan birthday celebration         0.640000   \n521   41304                             menu ensures         0.600000   \n512   41304                         time gettogether         0.497273   \n\n    sentiment_label                                   what_people_said  \n525            best      good stop splendid evening vegetarian lover .  \n510            best  food great spread expectation also good.. over...  \n511            best  food great spread expectation also good.. over...  \n521            best          huge spread menu ensures everyone happy .  \n512            good  friend long time gettogether.. really good chi...  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rest_id</th>\n      <th>menu_item</th>\n      <th>sentiment_score</th>\n      <th>sentiment_label</th>\n      <th>what_people_said</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>525</th>\n      <td>41304</td>\n      <td>splendid evening</td>\n      <td>0.766667</td>\n      <td>best</td>\n      <td>good stop splendid evening vegetarian lover .</td>\n    </tr>\n    <tr>\n      <th>510</th>\n      <td>41304</td>\n      <td>group hv quality</td>\n      <td>0.640000</td>\n      <td>best</td>\n      <td>food great spread expectation also good.. over...</td>\n    </tr>\n    <tr>\n      <th>511</th>\n      <td>41304</td>\n      <td>family dinner plan birthday celebration</td>\n      <td>0.640000</td>\n      <td>best</td>\n      <td>food great spread expectation also good.. over...</td>\n    </tr>\n    <tr>\n      <th>521</th>\n      <td>41304</td>\n      <td>menu ensures</td>\n      <td>0.600000</td>\n      <td>best</td>\n      <td>huge spread menu ensures everyone happy .</td>\n    </tr>\n    <tr>\n      <th>512</th>\n      <td>41304</td>\n      <td>time gettogether</td>\n      <td>0.497273</td>\n      <td>good</td>\n      <td>friend long time gettogether.. really good chi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Now we will be merging all frames using pandas join method to arrive at final output\n## Final output looks like\n### COLLECTION DETAILS | RESTAURANT DETAILS | MENU ITEMS | SENTI SCORE of what people said about menu "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_restaurant[['collection_id']] = df_restaurant[['collection_id']].apply(pd.to_numeric) ",
            "execution_count": 150,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_temp1 = pd.merge(df_collections,df_restaurant,on='collection_id',how='inner') #merged collections with resto frame",
            "execution_count": 151,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_final = pd.merge(df_temp1,df_analyzed_reviews,on='rest_id',how='inner') #merged with analyzed reviews",
            "execution_count": 152,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "unwanted_columns=['collection_id','res_count']\ndf_final = df_final.drop(columns=unwanted_columns,axis=1)",
            "execution_count": 153,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_final = df_final.reset_index(drop=True)",
            "execution_count": 154,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_final.head()",
            "execution_count": 155,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 155,
                    "data": {
                        "text/plain": "                                  description               title   rest_id  \\\n0  Most popular restaurants in town this week  Trending This Week  19296768   \n1  Most popular restaurants in town this week  Trending This Week  19296768   \n2  Most popular restaurants in town this week  Trending This Week  19296768   \n3  Most popular restaurants in town this week  Trending This Week  19296768   \n4  Most popular restaurants in town this week  Trending This Week  19296768   \n\n          rest_name rest_locality rest_user_rating         menu_item  \\\n0  Mitron At George          Fort              3.9  pav bhaji fondue   \n1  Mitron At George          Fort              3.9   mitron triangle   \n2  Mitron At George          Fort              3.9     triangle good   \n3  Mitron At George          Fort              3.9       corn cheese   \n4  Mitron At George          Fort              3.9     cinnamon star   \n\n   sentiment_score sentiment_label  \\\n0              1.0            best   \n1              0.7            best   \n2              0.7            best   \n3              0.7            best   \n4              0.6            best   \n\n                                    what_people_said  \n0                   pav bhaji fondue must one best .  \n1  mitron triangle good like patti samosa stuffed...  \n2  mitron triangle good like patti samosa stuffed...  \n3  mitron triangle good like patti samosa stuffed...  \n4   amazing cocktail flavoured cinnamon star anise .  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>description</th>\n      <th>title</th>\n      <th>rest_id</th>\n      <th>rest_name</th>\n      <th>rest_locality</th>\n      <th>rest_user_rating</th>\n      <th>menu_item</th>\n      <th>sentiment_score</th>\n      <th>sentiment_label</th>\n      <th>what_people_said</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Most popular restaurants in town this week</td>\n      <td>Trending This Week</td>\n      <td>19296768</td>\n      <td>Mitron At George</td>\n      <td>Fort</td>\n      <td>3.9</td>\n      <td>pav bhaji fondue</td>\n      <td>1.0</td>\n      <td>best</td>\n      <td>pav bhaji fondue must one best .</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Most popular restaurants in town this week</td>\n      <td>Trending This Week</td>\n      <td>19296768</td>\n      <td>Mitron At George</td>\n      <td>Fort</td>\n      <td>3.9</td>\n      <td>mitron triangle</td>\n      <td>0.7</td>\n      <td>best</td>\n      <td>mitron triangle good like patti samosa stuffed...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Most popular restaurants in town this week</td>\n      <td>Trending This Week</td>\n      <td>19296768</td>\n      <td>Mitron At George</td>\n      <td>Fort</td>\n      <td>3.9</td>\n      <td>triangle good</td>\n      <td>0.7</td>\n      <td>best</td>\n      <td>mitron triangle good like patti samosa stuffed...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Most popular restaurants in town this week</td>\n      <td>Trending This Week</td>\n      <td>19296768</td>\n      <td>Mitron At George</td>\n      <td>Fort</td>\n      <td>3.9</td>\n      <td>corn cheese</td>\n      <td>0.7</td>\n      <td>best</td>\n      <td>mitron triangle good like patti samosa stuffed...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Most popular restaurants in town this week</td>\n      <td>Trending This Week</td>\n      <td>19296768</td>\n      <td>Mitron At George</td>\n      <td>Fort</td>\n      <td>3.9</td>\n      <td>cinnamon star</td>\n      <td>0.6</td>\n      <td>best</td>\n      <td>amazing cocktail flavoured cinnamon star anise .</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "good_sentiments = ['best', 'good']\ndf_final = df_final.loc[df_final['sentiment_label'].isin(good_sentiments)]",
            "execution_count": 156,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_final.head()",
            "execution_count": 157,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 157,
                    "data": {
                        "text/plain": "                                  description               title   rest_id  \\\n0  Most popular restaurants in town this week  Trending This Week  19296768   \n1  Most popular restaurants in town this week  Trending This Week  19296768   \n2  Most popular restaurants in town this week  Trending This Week  19296768   \n3  Most popular restaurants in town this week  Trending This Week  19296768   \n4  Most popular restaurants in town this week  Trending This Week  19296768   \n\n          rest_name rest_locality rest_user_rating         menu_item  \\\n0  Mitron At George          Fort              3.9  pav bhaji fondue   \n1  Mitron At George          Fort              3.9   mitron triangle   \n2  Mitron At George          Fort              3.9     triangle good   \n3  Mitron At George          Fort              3.9       corn cheese   \n4  Mitron At George          Fort              3.9     cinnamon star   \n\n   sentiment_score sentiment_label  \\\n0              1.0            best   \n1              0.7            best   \n2              0.7            best   \n3              0.7            best   \n4              0.6            best   \n\n                                    what_people_said  \n0                   pav bhaji fondue must one best .  \n1  mitron triangle good like patti samosa stuffed...  \n2  mitron triangle good like patti samosa stuffed...  \n3  mitron triangle good like patti samosa stuffed...  \n4   amazing cocktail flavoured cinnamon star anise .  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>description</th>\n      <th>title</th>\n      <th>rest_id</th>\n      <th>rest_name</th>\n      <th>rest_locality</th>\n      <th>rest_user_rating</th>\n      <th>menu_item</th>\n      <th>sentiment_score</th>\n      <th>sentiment_label</th>\n      <th>what_people_said</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Most popular restaurants in town this week</td>\n      <td>Trending This Week</td>\n      <td>19296768</td>\n      <td>Mitron At George</td>\n      <td>Fort</td>\n      <td>3.9</td>\n      <td>pav bhaji fondue</td>\n      <td>1.0</td>\n      <td>best</td>\n      <td>pav bhaji fondue must one best .</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Most popular restaurants in town this week</td>\n      <td>Trending This Week</td>\n      <td>19296768</td>\n      <td>Mitron At George</td>\n      <td>Fort</td>\n      <td>3.9</td>\n      <td>mitron triangle</td>\n      <td>0.7</td>\n      <td>best</td>\n      <td>mitron triangle good like patti samosa stuffed...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Most popular restaurants in town this week</td>\n      <td>Trending This Week</td>\n      <td>19296768</td>\n      <td>Mitron At George</td>\n      <td>Fort</td>\n      <td>3.9</td>\n      <td>triangle good</td>\n      <td>0.7</td>\n      <td>best</td>\n      <td>mitron triangle good like patti samosa stuffed...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Most popular restaurants in town this week</td>\n      <td>Trending This Week</td>\n      <td>19296768</td>\n      <td>Mitron At George</td>\n      <td>Fort</td>\n      <td>3.9</td>\n      <td>corn cheese</td>\n      <td>0.7</td>\n      <td>best</td>\n      <td>mitron triangle good like patti samosa stuffed...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Most popular restaurants in town this week</td>\n      <td>Trending This Week</td>\n      <td>19296768</td>\n      <td>Mitron At George</td>\n      <td>Fort</td>\n      <td>3.9</td>\n      <td>cinnamon star</td>\n      <td>0.6</td>\n      <td>best</td>\n      <td>amazing cocktail flavoured cinnamon star anise .</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_final.to_csv('final.csv')",
            "execution_count": 158,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "try:\n    file1_from = 'final.csv'\n    file1_to = '/DataScience/final1.csv'\n\n    upload_file(file1_from,file1_to)\nexcept:\n    pass",
            "execution_count": 159,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}