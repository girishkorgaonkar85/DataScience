{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# RESTAURANT DISH RECOMMENDER SYSTEM"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### I poped into one of the restaurant's today & was confused after seeing the long menu card and innovative names. \n#### Sometimes a common man might not know what the dish actually means so he just needs to know what do I order from this long menu.\n#### In such cases earlier reviews might be helpful but there is lot of noise in it and you need to find out which dishes people are recommending.\n#### This program will read all the restaurant, review information from Zomato and do a basic sentiment analysis telling the top 3 dishes in each restaurant"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Lets begin by installing some libraries we would require"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "!pip install dropbox",
            "execution_count": 223,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Requirement already satisfied: dropbox in /opt/conda/envs/Python36/lib/python3.6/site-packages (9.4.0)\nRequirement already satisfied: six>=1.3.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from dropbox) (1.12.0)\nRequirement already satisfied: requests>=2.16.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from dropbox) (2.21.0)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests>=2.16.2->dropbox) (2.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests>=2.16.2->dropbox) (2019.9.11)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests>=2.16.2->dropbox) (3.0.4)\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests>=2.16.2->dropbox) (1.24.1)\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!pip install contractions",
            "execution_count": 224,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Requirement already satisfied: contractions in /opt/conda/envs/Python36/lib/python3.6/site-packages (0.0.24)\r\nRequirement already satisfied: textsearch in /opt/conda/envs/Python36/lib/python3.6/site-packages (from contractions) (0.0.17)\r\nRequirement already satisfied: pyahocorasick in /opt/conda/envs/Python36/lib/python3.6/site-packages (from textsearch->contractions) (1.4.0)\r\nRequirement already satisfied: Unidecode in /opt/conda/envs/Python36/lib/python3.6/site-packages (from textsearch->contractions) (1.1.1)\r\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!pip install TextBlob",
            "execution_count": 225,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Requirement already satisfied: TextBlob in /opt/conda/envs/Python36/lib/python3.6/site-packages (0.15.3)\r\nRequirement already satisfied: nltk>=3.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from TextBlob) (3.4)\r\nRequirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from nltk>=3.1->TextBlob) (1.12.0)\r\nRequirement already satisfied: singledispatch in /opt/conda/envs/Python36/lib/python3.6/site-packages (from nltk>=3.1->TextBlob) (3.4.0.3)\r\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## I will be doing REST API calls to ZOMATO API so importing libraries needed for it"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import requests as rq\nimport json\nimport pandas as pd\nimport dropbox\nfrom pandas.io.json import json_normalize",
            "execution_count": 226,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "headers = {}",
            "execution_count": 227,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Lets begin by defining a module for each function"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def initialize(api_key):\n    '''\n    func to intialize the headers for the request URL like api key etc.\n    '''\n    headers = {\n    'Accept': 'application/json',\n    'user-key': api_key,\n    }\n    return headers",
            "execution_count": 228,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def make_query(func,args):\n\n    '''\n    func - the call made to the API. eg. reviews/locations/restaurants/collections etc\n    args - arguments to be passed alongwith a particular func call\n    '''\n\n    #construct the query\n    req_url = \"https://developers.zomato.com/api/v2.1/\"\n    req_url=req_url+func\n    key_index=0\n    for key, value in args.items() :\n        if key_index == 0:\n            req_url=req_url+\"?\"+key+\"=\"+value\n        else:\n            req_url=req_url+\"&\"+key+\"=\"+value\n        key_index+=1\n    \n    return execute_query(req_url)",
            "execution_count": 229,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def execute_query(query):\n    '''\n    query - object of class zomatoApiRequest\n    headers - dict of meta data for API call\n    '''\n    response=rq.get(query,headers=headers)\n    return(response.json())",
            "execution_count": 230,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def getLocation(location_name):\n    '''\t\n    get details of most relevant locations searched by name\n    '''\n    func = \"locations\"\n    args = { 'query': location_name }\n    output = make_query(func,args)\n    if (checkKey(output,'location_suggestions') == 1):\n        print(\"location found\")\n    else:\n        print(\"location key not found in this iteration\")\n    return output['location_suggestions'][0]",
            "execution_count": 233,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def getCollections(city_id):\n    '''\t\n    get details of collection\n    '''\n    func = \"collections\"\n    args =dict()\n    args[\"city_id\"] = city_id\n    output = make_query(func,args)\n    if (checkKey(output,'collections') == 1):\n        print(\"collections found \")\n    else:\n        print(\"collections key not found in this iteration\")\n    return(output['collections'])",
            "execution_count": 234,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def getReviews(res_id):\n    '''\t\n    get details of reviews\n    '''\n    func = \"reviews\"\n    args =dict()\n    args[\"res_id\"] = res_id\n    output = make_query(func,args)\n    if (checkKey(output,'reviews_shown') == 1):\n        print(\"reviews found\")\n    else:\n        print(\"reviews key not found in this iteration\")\n    return(output['user_reviews'])",
            "execution_count": 235,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def search(city_id,collection_id,start=0,count=1):\n    '''\n    get restaurants for the given location(entity_id); other args - cuisines/collections/category and sorting & counts for fetching how many at a time\n    '''\n    func = \"search\"\n    args = { 'entity_id':city_id, 'entity_type':'city', 'start':str(start), 'count':str(count),'collection_id':collection_id,'sort':'rating','order':'desc'}\n    output = make_query(func,args)\n    return(output)",
            "execution_count": 236,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def checkKey(dict, key):\n    '''\t\n    func to check if a dictionary key exists before taking any actions on it\n    '''\n    if key in dict.keys(): \n        return 1\n    else: \n        return 0",
            "execution_count": 237,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def extract_resto_and_reviews(collection_id,output,total_results):\n    '''\t\n    func to extract all restaurants within a collection. This will iterate multiple times as one API call gives on 20 restaurants\n    We will populate all the data from the JSON objects into individual lists & finally append to a dictonary which can be easily converted to a pandas frame\n    '''\n    restro_temp_list = []\n    resto_index = 0\n    restro_temp_list.append(output['restaurants'])\n    #print(\"Length of resto temp list \",len(restro_temp_list))\n    for i in range(0,len(restro_temp_list)): #always len(restro_temp_list) = 1 \n        try:\n            for rest_dict_val in restro_temp_list[i]: #loop for restaturants within a collection                   \n\n                if resto_index <=total_results: #till we get data for all restaurants in this collection  \n                    if (checkKey(rest_dict_val,'restaurant') == 1):\n                        #print(\"processing res_id \", rest_dict_val['restaurant']['id'])\n                        collection_id_list.append(collection_id)\n                        rest_id_list.append(rest_dict_val['restaurant']['id'])\n                        rest_name_list.append(rest_dict_val['restaurant']['name'])\n                        rest_locality_list.append(rest_dict_val['restaurant']['location']['locality'])\n                        rest_user_rating_list.append(rest_dict_val['restaurant']['user_rating']['aggregate_rating'])\n\n                        rev_output_list = getReviews(str(rest_dict_val['restaurant']['id']))\n\n                        for rev_text_dict_val in rev_output_list: #loop for reviews within a restaurant\n                            if (checkKey(rev_text_dict_val,'review') == 1):\n                                if rev_text_dict_val['review']['review_text'] != '':\n                                    review_rest_id_list.append(rest_dict_val['restaurant']['id'])\n                                    review_id_list.append(rev_text_dict_val['review']['id'])\n                                    review_text_list.append(rev_text_dict_val['review']['review_text'])\n                                    review_rating_list.append(rev_text_dict_val['review']['rating'])                        \n\n                        resto_index = resto_index+1 \n        except KeyError:\n            pass",
            "execution_count": 238,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def exhaustiveSearch(city_id,collection_id,collection_res_count):\n    '''\n    The basic call to SEARCH API of ZOMATO\n    API allows retrieving only upto 20 results at a time so we interate in same collection till all restaurants obtained\n    '''\n    start = 0\n    cnt = 20\n    resto_index = 0\n    offset = start\n    \n    output = search(city_id,collection_id,start=offset,count=cnt)\n    total_results = output['results_shown']\n    #print(\"results_shown = \", total_results)\n    #print(\"collection_res_count = \",collection_res_count)\n    \n    if total_results == collection_res_count: #1st extraction itself gave all restaurants\n        print(\"ONLY 1 CALL ENOUGH to get all restaurants\")        \n        extract_resto_and_reviews(collection_id,output,total_results)               \n    else:\n        print(\"WILL BE DOING MORE CALLS to get all restaurants\")\n        extract_resto_and_reviews(collection_id,output,total_results) #1st extraction as is since output is already obtained above \n        \n        offset = start+total_results #determine new offset for next search\n                \n        while (offset <=collection_res_count):\n            #print(\"offset=\",offset)\n            output = search(city_id,collection_id,start=offset,count=cnt)\n            \n            total_results = output['results_shown']\n            print(\"new results_shown = \", total_results)\n            \n            extract_resto_and_reviews(collection_id,output,total_results)\n            \n            offset = offset+total_results #determine new offset for next search\n            if(total_results == 0): #no more results coming\n                print(\"no more restaurants data to fetch\")\n                break\n                \n    all_review_data = {'rest_id':review_rest_id_list,'review_id':review_id_list, \n                       'review_text':review_text_list,'review_rating':review_rating_list}\n    all_resto_data = {'collection_id':collection_id_list,'rest_id':rest_id_list, \n                  'rest_name':rest_name_list,'rest_locality':rest_locality_list,\n                  'rest_user_rating':rest_user_rating_list} \n\n    return(all_resto_data,all_review_data)",
            "execution_count": 239,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## The MAIN code processing begins from here"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "if __name__ == \"__main__\":\n    api_key = \"19b2c1a3c8e2493d77b2231b99696407\"\n    headers = initialize(api_key)\n\n    user_location=input(\"Enter location:\")\n    \n    location_result = getLocation(user_location)\n    #print(location_result)\n    \n    collection_list = getCollections(str(location_result['city_id']))",
            "execution_count": 241,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Enter location:Mumbai\nlocation found\ncollections found \n"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#collection_list",
            "execution_count": 242,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_collections = pd.DataFrame.from_dict(json_normalize(collection_list), orient='columns')",
            "execution_count": 243,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_collections.shape",
            "execution_count": 244,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 244,
                    "data": {
                        "text/plain": "(48, 7)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "new_columns={'collection.collection_id':'collection_id','collection.description':'description','collection.res_count':'res_count','collection.title':'title'}\nunwanted_columns=['collection.image_url','collection.share_url','collection.url']\ndf_collections = df_collections.rename(columns=new_columns)\ndf_collections = df_collections.drop(columns=unwanted_columns,axis=1)",
            "execution_count": 245,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_collections.head()",
            "execution_count": 246,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 246,
                    "data": {
                        "text/plain": "   collection_id                                        description  \\\n0              1         Most popular restaurants in town this week   \n1         274852  The hunt for the highest-rated restaurants in ...   \n2             29                        The best new places in town   \n3         304361                               Binge. Chug. Groove!   \n4            490    These eateries make healthy food a tasty affair   \n\n   res_count                                              title  \n0         30                                 Trending This Week  \n1        250                                Great Food, No Bull  \n2         32                                       Newly Opened  \n3         15   Mumbai's Best Food & Party Destination - The Orb  \n4         32                                     Healthy Living  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>collection_id</th>\n      <th>description</th>\n      <th>res_count</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Most popular restaurants in town this week</td>\n      <td>30</td>\n      <td>Trending This Week</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>274852</td>\n      <td>The hunt for the highest-rated restaurants in ...</td>\n      <td>250</td>\n      <td>Great Food, No Bull</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29</td>\n      <td>The best new places in town</td>\n      <td>32</td>\n      <td>Newly Opened</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>304361</td>\n      <td>Binge. Chug. Groove!</td>\n      <td>15</td>\n      <td>Mumbai's Best Food &amp; Party Destination - The Orb</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>490</td>\n      <td>These eateries make healthy food a tasty affair</td>\n      <td>32</td>\n      <td>Healthy Living</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## We have now collected all the collections & I will only fetch data for first 4 collections in this program"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_sample_collection = df_collections.head(4)",
            "execution_count": 247,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_sample_collection",
            "execution_count": 248,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 248,
                    "data": {
                        "text/plain": "   collection_id                                        description  \\\n0              1         Most popular restaurants in town this week   \n1         274852  The hunt for the highest-rated restaurants in ...   \n2             29                        The best new places in town   \n3         304361                               Binge. Chug. Groove!   \n\n   res_count                                              title  \n0         30                                 Trending This Week  \n1        250                                Great Food, No Bull  \n2         32                                       Newly Opened  \n3         15   Mumbai's Best Food & Party Destination - The Orb  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>collection_id</th>\n      <th>description</th>\n      <th>res_count</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Most popular restaurants in town this week</td>\n      <td>30</td>\n      <td>Trending This Week</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>274852</td>\n      <td>The hunt for the highest-rated restaurants in ...</td>\n      <td>250</td>\n      <td>Great Food, No Bull</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29</td>\n      <td>The best new places in town</td>\n      <td>32</td>\n      <td>Newly Opened</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>304361</td>\n      <td>Binge. Chug. Groove!</td>\n      <td>15</td>\n      <td>Mumbai's Best Food &amp; Party Destination - The Orb</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Creating dataframe objects to hold review & restaurant data"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_reviews = pd.DataFrame(columns = ['rest_id', 'review_id','review_text','review_rating'])\ndf_restaurant = pd.DataFrame(columns = ['collection_id','rest_id', 'rest_name','rest_locality','rest_user_rating'])",
            "execution_count": 249,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## For every collection we get all restos & their reviews"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "for index in df_sample_collection.index: #loop over each collection (4 for now)\n    all_review_data = {}\n    all_resto_data = {}\n    rest_id_list = []\n    rest_name_list = []\n    rest_locality_list = []\n    rest_user_rating_list = []\n    collection_id_list = []\n    review_rest_id_list = []\n    review_id_list = []  \n    review_text_list = []\n    review_rating_list = []\n    \n    coll_res_count = df_sample_collection['res_count'][index]\n    print(\"processing collection = \",df_sample_collection['collection_id'][index])\n    \n    all_resto_data,all_review_data = exhaustiveSearch(str(location_result['city_id']),str(df_sample_collection['collection_id'][index]),coll_res_count)\n    df_restaurant = df_restaurant.append(pd.DataFrame(all_resto_data),ignore_index=True) #append all resto data to a frame\n    df_reviews = df_reviews.append(pd.DataFrame(all_review_data),ignore_index=True) #append all resto data to a frame\n    print(\"\")\n\nprint(\"processed all collections\")",
            "execution_count": 250,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "processing collection =  1\nONLY 1 CALL ENOUGH to get all restaurants\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\n\nprocessing collection =  274852\nWILL BE DOING MORE CALLS to get all restaurants\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nnew results_shown =  20\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nnew results_shown =  20\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nnew results_shown =  20\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nnew results_shown =  20\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews key not found in this iteration\nnew results_shown =  0\nno more restaurants data to fetch\n\nprocessing collection =  29\nWILL BE DOING MORE CALLS to get all restaurants\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nnew results_shown =  12\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nreviews found\nnew results_shown =  0\nno more restaurants data to fetch\n\nprocessing collection =  304361\nONLY 1 CALL ENOUGH to get all restaurants\nreviews found\nreviews found\nreviews found\nreviews key not found in this iteration\n\nprocessed all collections\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## We have now collected restaurant and review data in pandas. Optionally you can export this to a dropbox for reviewing independtly on your PC\n## Use your DROPBOX API key in below function"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def upload_file(file_from, file_to):\n    dbx = dropbox.Dropbox(\"JRedVn3NSbAAAAAAAAAAHILFf6nwfXdAL3zdcH7N1INQXlpsfky6X6CUZ_g7qtuI\")\n    f = open(file_from, 'rb')\n    dbx.files_upload(f.read(), file_to) ",
            "execution_count": 251,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## There is possibility that a resturant might be scanned in mutliple collections for purpose of further analysis lets remove duplicates"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_restaurant = df_restaurant.drop_duplicates(['rest_id'], keep='first')\ndf_restaurant = df_restaurant.reset_index(drop=True)\ndf_reviews = df_reviews.drop_duplicates(['review_id'], keep='first')\ndf_reviews = df_reviews.reset_index(drop=True)",
            "execution_count": 253,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_restaurant.shape",
            "execution_count": 254,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 254,
                    "data": {
                        "text/plain": "(159, 5)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_reviews.shape",
            "execution_count": 255,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 255,
                    "data": {
                        "text/plain": "(601, 4)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_restaurant.to_csv('restaurant.csv', header=True)\ndf_reviews.to_csv('reviews.csv', header=True)",
            "execution_count": 256,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#file1_from = 'restaurant.csv'\n#file1_to = '/DataScience/restaurant.csv'\n#file2_from = 'reviews.csv'\n#file2_to = '/DataScience/reviews.csv'\n\n#upload_file(file1_from,file1_to)\n#upload_file(file2_from,file2_to)",
            "execution_count": 257,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#df_restaurant['rest_id'].value_counts()",
            "execution_count": 258,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#df_reviews['review_id'].value_counts()",
            "execution_count": 259,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Now I am importing libraries needed for NLP like NLTK, Text Blob, Spacy"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import nltk\nimport re\nimport unicodedata\nimport contractions\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import sent_tokenize\nfrom textblob import TextBlob",
            "execution_count": 260,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "nltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('brown')\nnltk.download('averaged_perceptron_tagger')",
            "execution_count": 261,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/dsxuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /home/dsxuser/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /home/dsxuser/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package brown to /home/dsxuser/nltk_data...\n[nltk_data]   Package brown is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/dsxuser/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n",
                    "name": "stderr"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 261,
                    "data": {
                        "text/plain": "True"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "stopword = stopwords.words('english')\nto_remove = ['and', 'the']\nnew_stopwords = list(set(stopword).difference(to_remove))",
            "execution_count": 262,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Defining function for each task in NLP pre-processing"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def to_lowercase(text):\n    return text.lower()",
            "execution_count": 263,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def remove_html(text):\n    return (re.sub('<[^<]+?>','', text))",
            "execution_count": 264,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def remove_non_ascii(text):\n    return (unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore'))",
            "execution_count": 265,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def remove_punctuations(text):\n    return (re.sub('[~!@#$%^&?,:\";-]', '', text))",
            "execution_count": 266,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def remove_numbers(text):\n    return (''.join(c for c in text if not c.isdigit()))",
            "execution_count": 267,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def remove_stopwords(text):\n    word_tokens = nltk.word_tokenize(text)\n    return(' '.join([word for word in word_tokens if word not in new_stopwords]))",
            "execution_count": 268,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def lemmatize(text):\n    wordnet_lemmatizer = WordNetLemmatizer()\n    word_tokens = nltk.word_tokenize(text)\n    return ' '.join([wordnet_lemmatizer.lemmatize(word) for word in word_tokens])",
            "execution_count": 166,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def remove_contractions(text):\n    '''func to convert contractions to full words e.g. can't will become cannot'''\n    return ' '.join([contractions.fix(word) for word in text.split()])",
            "execution_count": 269,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def do_spell_corrections(text_blob):\n    return(text_blob.correct())",
            "execution_count": 270,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def get_ngram_noun_phrases(sentence, ngrams = 2):\n    '''\n    func to get all noun phrases using Text Blob. A dish name might be all nouns but could be a 2 letter word or 3 or 4 or 5\n    this will extract all noun phrases from the review's blob objects and put in a list\n    '''\n    sent_blob = TextBlob(str(sentence))\n    ngram_list = sent_blob.ngrams(n=ngrams)   \n    #print(ngram_list)\n    #print(\"\")\n    for pair in ngram_list:\n        ngram = ' '.join(pair)\n        word_blob = TextBlob(ngram)\n        for np in word_blob.noun_phrases:\n            #print(np)\n            if np not in noun_phrases_list:\n                noun_phrases_list.append(np)",
            "execution_count": 271,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def clean_review(text,is_Lower=True,remove_html=True,remove_nascii=True,remove_punct=True,remove_cont=True,remove_stop=True,is_lemma=False):\n    '''\n    func to pre-process the review text. You can toggle a param if you dont want particular pre-processing task to happen\n    '''\n    if is_Lower:\n        text = to_lowercase(text)\n    elif remove_html:\n        text= remove_html(text)\n    elif remove_nascii:\n        text= remove_non_ascii(text)\n    elif remove_punct:\n        text= remove_punctuations(text)\n    elif remove_cont:\n        text= remove_contractions(text)\n    elif remove_stop:\n        text= remove_stopwords(text)\n    elif is_lemm:\n        text= lemmatize(text)\n    return (text)    ",
            "execution_count": 272,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def sentiment_textblob(feedback): \n    '''\n    func to map the sentence polarity to a user defined sentiment label\n    '''\n    senti = TextBlob(feedback) \n    polarity = senti.sentiment.polarity \n    if -1 <= polarity < -0.5: \n        label = 'very bad' \n    elif -0.5 <= polarity < -0.1: \n        label = 'bad' \n    elif -0.1 <= polarity < 0.2: \n        label = 'ok' \n    elif 0.2 <= polarity < 0.6: \n        label = 'good' \n    elif 0.6 <= polarity <= 1: \n        label = 'best' \n    \n    return (polarity, label) ",
            "execution_count": 273,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def generate_noun_pharses(rev_blob):\n    '''\n    func to generate all bnoun phrases from a blob object\n    '''\n    for sent in rev_blob.sentences:   \n        get_ngram_noun_phrases(sent,2) #bigram phrases\n        get_ngram_noun_phrases(sent,3) #trigram phrases\n        get_ngram_noun_phrases(sent,4) \n        get_ngram_noun_phrases(sent,5)",
            "execution_count": 274,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def generate_possible_menu_list(noun_phrases_list):\n    '''\n    func that will create a list where the noun phrase contains all nouns which means its a possible dish name\n    '''\n    for element in noun_phrases_list:\n        tag_list = []\n        phrase_blob = TextBlob(element)\n        tag_list = phrase_blob.tags\n        #print(\"tag_list \",tag_list)\n        if ((tag_list[0][1] == 'NN' or tag_list[0][1] == 'NNS') and (tag_list[-1][1] == 'NN' or tag_list[-1][1] == 'NNS')):\n            possible_menu_list.append(element)",
            "execution_count": 275,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def remove_duplicate_noun_phrases(possible_menu_list):\n    '''\n    We could get similar dish names while parsing each noun phrase\n    e.g. chicken noodles vs spicy chicken noodles. In such cases will keep only the phrase with longest length\n    '''\n    for i, elements in enumerate(possible_menu_list):\n        try:\n            thiselem = str(elements)\n            matching_elements = [s for s in possible_menu_list if thiselem in s]\n            #print(matching_elements)\n            for j, val in enumerate(matching_elements):\n                curr_val = str(val)\n                next_val = str(matching_elements[(j + 1) % len(matching_elements)])\n\n                if len(curr_val) > len(next_val):\n                    #print(\"Removing \",next_val)\n                    if next_val not in exclude_list:\n                        exclude_list.append(next_val)\n                elif len(curr_val) < len(next_val):\n                    #print(\"Removing \",curr_val)\n                    if curr_val not in exclude_list:\n                        exclude_list.append(curr_val)\n        except:\n            pass\n    \n    for x in exclude_list:\n        try:\n            possible_menu_list.remove(x)\n        except:\n            pass",
            "execution_count": 276,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def analyze_review_to_get_menu_and_sentiment(rev_id,text):\n    '''\n    func to analyze each review text\n    1. Convert to a BLOB\n    2. Optional spell correct. Turned this off because if spelling changes then searching in actual text becomes difficult\n    3. Get noun phrases\n    4. Get possible menu list items (all nouns POS)\n    5. Retain menu items with max length\n    6. Search each item with each sentence of the given review text and if found\n       a. Get sentiment score, label of that sentence\n       b. break\n       c. Store in list for adding to a pandas frame\n    '''\n    \n    cl_review = clean_review(text,True,True,True,True,True,True,False)\n    cl_review_s = clean_review(text,True,True,True,True,True,False,False)\n    \n    rev_blob = TextBlob(cl_review)\n    rev_blob_s = TextBlob(cl_review_s)\n    \n    #rev_blob = do_spell_corrections(rev_blob)\n    #rev_blob_s = do_spell_corrections(rev_blob_s)\n    \n    generate_noun_pharses(rev_blob)\n    #print(\"noun_phrases_list = \", noun_phrases_list)\n    \n    generate_possible_menu_list(noun_phrases_list)\n    #print(\"possible menu_list = \",possible_menu_list) \n    \n    remove_duplicate_noun_phrases(possible_menu_list)\n    #print(\"possible menu_list after duplicates removal=\",possible_menu_list)\n    \n    raw_sentence_list = sent_tokenize(str(rev_blob_s))\n    \n    detected_sentence = ''\n    polarity= -99 \n    label = ''\n    for m in possible_menu_list:\n        for sentence in raw_sentence_list:\n            if m in sentence:\n                (polarity, label) = sentiment_textblob(str(sentence))\n                \n                detected_sentence = sentence\n                break\n        rev_id_list.append(rev_id)\n        menu_item_list.append(m)\n        detected_sentence_list.append(detected_sentence)\n        sent_polarity_list.append(polarity)\n        sentiment_label_list.append(label)",
            "execution_count": 277,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#df_reviews = df_reviews.drop(columns=\"clean_review_text\",axis=1)",
            "execution_count": 278,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Using the clean function to create a column for cleaned review for reference"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_reviews['clean_review_text'] = df_reviews.review_text.apply(clean_review)",
            "execution_count": 281,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_reviews.head()",
            "execution_count": 282,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 282,
                    "data": {
                        "text/plain": "    rest_id review_id                                        review_text  \\\n0  18234205  46259136  One Street Bandra, the elder sister of Bastian...   \n1  18234205  45648284  Ashish was really good at serving us, his reco...   \n2  18365166  46457602  Went there in a group of 10 on Friday night, t...   \n3  18365166  41084301  Hideout cafe.. it's really hidden place.... Bu...   \n4  18365166  40358430  Hideout caf\u00e9 hides in plain sight at the High ...   \n\n  review_rating                                  clean_review_text  \n0             4  one street bandra, the elder sister of bastian...  \n1             4  ashish was really good at serving us, his reco...  \n2             4  went there in a group of 10 on friday night, t...  \n3             5  hideout cafe.. it's really hidden place.... bu...  \n4             4  hideout caf\u00e9 hides in plain sight at the high ...  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rest_id</th>\n      <th>review_id</th>\n      <th>review_text</th>\n      <th>review_rating</th>\n      <th>clean_review_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18234205</td>\n      <td>46259136</td>\n      <td>One Street Bandra, the elder sister of Bastian...</td>\n      <td>4</td>\n      <td>one street bandra, the elder sister of bastian...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18234205</td>\n      <td>45648284</td>\n      <td>Ashish was really good at serving us, his reco...</td>\n      <td>4</td>\n      <td>ashish was really good at serving us, his reco...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18365166</td>\n      <td>46457602</td>\n      <td>Went there in a group of 10 on Friday night, t...</td>\n      <td>4</td>\n      <td>went there in a group of 10 on friday night, t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18365166</td>\n      <td>41084301</td>\n      <td>Hideout cafe.. it's really hidden place.... Bu...</td>\n      <td>5</td>\n      <td>hideout cafe.. it's really hidden place.... bu...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18365166</td>\n      <td>40358430</td>\n      <td>Hideout caf\u00e9 hides in plain sight at the High ...</td>\n      <td>4</td>\n      <td>hideout caf\u00e9 hides in plain sight at the high ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Processing all reviews from reviews frame and store in new frame"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_analyzed_reviews = pd.DataFrame(columns = ['review_id','menu_item','sentiment_score','sentiment_label','what_people_said'])\nfor index in df_reviews.index: #loop over each review\n    #print(\"processing review = \",df_reviews['review_id'][index])\n    \n    rev_id_list = []\n    menu_item_list = []\n    detected_sentence_list = []\n    sent_polarity_list = []\n    sentiment_label_list = []\n    \n    noun_phrases_list = []\n    possible_menu_list = []\n    exclude_list = []\n    raw_sentence_list=[]\n    \n    analyze_review_to_get_menu_and_sentiment(df_reviews['review_id'][index],str(df_reviews['review_text'][index]))\n    \n    #print(menu_item_list)\n    #print(sent_polarity_list)\n    #print(sentiment_label_list)\n    #print(detected_sentence_list)\n    #break\n    \n    all_cleaned_review_data = {'review_id':rev_id_list,\n                           'menu_item':menu_item_list,'sentiment_score':sent_polarity_list,\n                           'sentiment_label':sentiment_label_list,'what_people_said':detected_sentence_list}\n\n    df_analyzed_reviews = df_analyzed_reviews.append(pd.DataFrame(all_cleaned_review_data),ignore_index=True) #append all analyzed review data to a frame\n\nprint(\"processed all reviews\")",
            "execution_count": 283,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "processed all reviews\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Lets sort each menu item within a review in descending order of score"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_analyzed_reviews = df_analyzed_reviews.sort_values(['review_id','sentiment_score'],ascending=[1, 0])",
            "execution_count": 284,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_analyzed_reviews.head()",
            "execution_count": 285,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 285,
                    "data": {
                        "text/plain": "   review_id             menu_item  sentiment_score sentiment_label  \\\n57  40174927            name suits         0.000000              ok   \n58  40174927            beer pizza         0.000000              ok   \n56  40323829           hukah place         0.500000            good   \n55  40323829  pink sauce spaghetti         0.334375            good   \n54  40358430          wine sangria         0.500000            good   \n\n                                     what_people_said  \n57  the name suits this cafe it's like you have to...  \n58  the name suits this cafe it's like you have to...  \n56          the ambiance was more of a hukah place...  \n55  this cafe was earlier famous for hukah... now ...  \n54  red wine sangria : again surprisingly awesome ...  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n      <th>menu_item</th>\n      <th>sentiment_score</th>\n      <th>sentiment_label</th>\n      <th>what_people_said</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>57</th>\n      <td>40174927</td>\n      <td>name suits</td>\n      <td>0.000000</td>\n      <td>ok</td>\n      <td>the name suits this cafe it's like you have to...</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>40174927</td>\n      <td>beer pizza</td>\n      <td>0.000000</td>\n      <td>ok</td>\n      <td>the name suits this cafe it's like you have to...</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>40323829</td>\n      <td>hukah place</td>\n      <td>0.500000</td>\n      <td>good</td>\n      <td>the ambiance was more of a hukah place...</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>40323829</td>\n      <td>pink sauce spaghetti</td>\n      <td>0.334375</td>\n      <td>good</td>\n      <td>this cafe was earlier famous for hukah... now ...</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>40358430</td>\n      <td>wine sangria</td>\n      <td>0.500000</td>\n      <td>good</td>\n      <td>red wine sangria : again surprisingly awesome ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Now we will be merging all frames using pandas join method to arrive at final output\n## Final output looks like\n### COLLECTION DETAILS | RESTAURANT DETAILS | MENU ITEMS | SENTI SCORE of what people said about menu "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_restaurant[['collection_id']] = df_restaurant[['collection_id']].apply(pd.to_numeric) ",
            "execution_count": 287,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_temp1 = pd.merge(df_collections,df_restaurant,on='collection_id',how='inner') #merged collections with resto frame",
            "execution_count": 288,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_temp2 = pd.merge(df_temp1,df_reviews,on='rest_id',how='inner') #merged with review frame",
            "execution_count": 289,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_final = pd.merge(df_temp2,df_analyzed_reviews,on='review_id',how='inner') #merged with analyzed reviews",
            "execution_count": 290,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "unwanted_columns=['collection_id','res_count','rest_id','review_id','review_text']\ndf_final = df_final.drop(columns=unwanted_columns,axis=1)",
            "execution_count": 291,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_final.head()",
            "execution_count": 292,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 292,
                    "data": {
                        "text/plain": "                                  description               title   rest_name  \\\n0  Most popular restaurants in town this week  Trending This Week  One Street   \n1  Most popular restaurants in town this week  Trending This Week  One Street   \n2  Most popular restaurants in town this week  Trending This Week  One Street   \n3  Most popular restaurants in town this week  Trending This Week  One Street   \n4  Most popular restaurants in town this week  Trending This Week  One Street   \n\n               rest_locality rest_user_rating review_rating  \\\n0  Linking Road, Bandra West              4.1             4   \n1  Linking Road, Bandra West              4.1             4   \n2  Linking Road, Bandra West              4.1             4   \n3  Linking Road, Bandra West              4.1             4   \n4  Linking Road, Bandra West              4.1             4   \n\n                                   clean_review_text            menu_item  \\\n0  one street bandra, the elder sister of bastian...        cookie stands   \n1  one street bandra, the elder sister of bastian...      chocolate sauce   \n2  one street bandra, the elder sister of bastian...  comfort finger food   \n3  one street bandra, the elder sister of bastian...                  \u2019 s   \n4  one street bandra, the elder sister of bastian...     multiple options   \n\n   sentiment_score sentiment_label  \\\n0         1.000000            best   \n1         1.000000            best   \n2         0.533333            good   \n3         0.533333            good   \n4         0.525000            good   \n\n                                    what_people_said  \n0  the cookie stands out for its taste and goes p...  \n1  the cookie stands out for its taste and goes p...  \n2  for comfort finger food and good drinks, it of...  \n3  for comfort finger food and good drinks, it of...  \n4  the service is good, recommendations are excel...  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>description</th>\n      <th>title</th>\n      <th>rest_name</th>\n      <th>rest_locality</th>\n      <th>rest_user_rating</th>\n      <th>review_rating</th>\n      <th>clean_review_text</th>\n      <th>menu_item</th>\n      <th>sentiment_score</th>\n      <th>sentiment_label</th>\n      <th>what_people_said</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Most popular restaurants in town this week</td>\n      <td>Trending This Week</td>\n      <td>One Street</td>\n      <td>Linking Road, Bandra West</td>\n      <td>4.1</td>\n      <td>4</td>\n      <td>one street bandra, the elder sister of bastian...</td>\n      <td>cookie stands</td>\n      <td>1.000000</td>\n      <td>best</td>\n      <td>the cookie stands out for its taste and goes p...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Most popular restaurants in town this week</td>\n      <td>Trending This Week</td>\n      <td>One Street</td>\n      <td>Linking Road, Bandra West</td>\n      <td>4.1</td>\n      <td>4</td>\n      <td>one street bandra, the elder sister of bastian...</td>\n      <td>chocolate sauce</td>\n      <td>1.000000</td>\n      <td>best</td>\n      <td>the cookie stands out for its taste and goes p...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Most popular restaurants in town this week</td>\n      <td>Trending This Week</td>\n      <td>One Street</td>\n      <td>Linking Road, Bandra West</td>\n      <td>4.1</td>\n      <td>4</td>\n      <td>one street bandra, the elder sister of bastian...</td>\n      <td>comfort finger food</td>\n      <td>0.533333</td>\n      <td>good</td>\n      <td>for comfort finger food and good drinks, it of...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Most popular restaurants in town this week</td>\n      <td>Trending This Week</td>\n      <td>One Street</td>\n      <td>Linking Road, Bandra West</td>\n      <td>4.1</td>\n      <td>4</td>\n      <td>one street bandra, the elder sister of bastian...</td>\n      <td>\u2019 s</td>\n      <td>0.533333</td>\n      <td>good</td>\n      <td>for comfort finger food and good drinks, it of...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Most popular restaurants in town this week</td>\n      <td>Trending This Week</td>\n      <td>One Street</td>\n      <td>Linking Road, Bandra West</td>\n      <td>4.1</td>\n      <td>4</td>\n      <td>one street bandra, the elder sister of bastian...</td>\n      <td>multiple options</td>\n      <td>0.525000</td>\n      <td>good</td>\n      <td>the service is good, recommendations are excel...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}